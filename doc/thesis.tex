% зазначаємо стильовий файл, який будемо використовувати
\documentclass{udstu}

\addbibresource{refs.bib}

% починаємо верстку документа
\begin{document}

\pagenumbering{gobble}

\makediplomatitle{
% StudentName --- прізвище, ініціали студента
	StudentName={Скороденко Дмитро Олександрович},
% StudentMale --- стать студента (true, якщо чоловік, false --- якщо жінка)
	StudentMale=true,
% StudentGroup --- група студента
	StudentGroup={КМ-01},
% Title --- назва
	Title={
		\textbf{
		{\large Дипломна робота} \\
		на здобуття ступеня бакалавра \\
		за освітньо-професійною програмою \\
		\invcommas{Наука про дані та математичне моделювання} \\
		спеціальності 113 \invcommas{Прикладна математика} \\
		на тему: \invcommas{Математичне та програмне забезпечення для автоматичного тегування зображень}
	}},
	Department={\ \ \ \ \ \ \ \ },
	HeadOfDepartment={\_\_\_\_\_\_\_\_ Олег Чертов},
% SupervisorDegree --- науковий ступінь, учене звання керівника роботи
% якщо наукового ступеня немає, можна відповідний рядочок пропустити
	SupervisorDegree={Доцент, к. т. н., доцент кафедри ПМА},
% SupervisorName --- прізвище, ініціали керівника роботи
	SupervisorName={Сирота Сергій Вікторович},
	ConsultDegree={Старший викладач},
	ConsultName={Мальчиков Володимир Вікторович},
	RecenzDegree={Доцент, канд. техн. наук, доцент кафедри ПЗКС},
	RecenzName={Онай Микола Володимирович},
}

\begin{enumerate}[1.]
	\item Тема роботи \invcommas{Математичне та програмне забезпечення для автоматичного тегування зображень},
	керівник роботи Сирота Сергій Вікторович, канд. техн. наук, доцент, затверджені наказом по університету
	від \invcommas{30} травня 2024 р. №2205-с .

	\item Термін подання студентом роботи \invcommas{10} червня 2024 р.

	\item Вихідні дані до роботи: спроектована модель для маркування зображень повинна
	забезпечити якість опису зображення краще або на рівні із існуючими рішеннями згідно із
	тестовими метриками.

	\item Зміст роботи: виконати огляд існуючих рішень задачі маркування зображення,
	провести моделювання на основі аналізу існуючих рішень, імплементація моделі,
	тренування / тестування моделі, аналіз ефективності компонентів,
	аналіз ефективності моделі у порівнянні із існуючими рішеннями.

	\item Перелік обов'язкового ілюстративного матеріалу: діаграма архітектури композитної моделі,
	розподіл лейблів у тренувальному/тестовому датасеті, числові характеристики датасету,
	графіки процесу тренування для кожної із компонент моделі,
	таблиця для порівняння ефективності компонентів моделі,
	таблиця для порівняння ефективносіт маркування у порівнянні з існуючими рішеннями,
	ілюстративні приклади роботи моделі.

	\item Дата видачі завдання \invcommas{05} лютого 2024 р.
\end{enumerate}

\begin{center}
	Календарний план
	\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
	\begin{longtable}{|P{0.05\textwidth}|P{0.4\textwidth}|P{0.25\textwidth}|P{0.15\textwidth}|}
			\hline
			№ з/п & Назва етапів виконання дипломної роботи & Термін виконання етапів роботи & Примітка \\
			\hline
			1.    & Вивчення та збір літератури за темою "маркування зображень" &
			25.01.2024 & + \\
			\hline
			2.    & Проведення аналізу особливостей існуючих систем маркування зображень &
			15.02.2024 & + \\
			\hline
			3.    & Вибір та підготовка датасету &
			25.02.2024 & + \\
			\hline
			4.    & Проектування моделі маркування зображення &
			10.03.2024 & + \\
			\hline
			5.    & Проведення тестового тренування моделі та відладка програми &
			25.03.2024 & + \\
			\hline
			6.    & Проведення валідації результатів тестового тренування &
			28.03.2024 & + \\
			\hline
			7.    & Проведення тренування фінальної версії моделі &
			14.04.2024 & + \\
			\hline
			8.    & Проведення порівняльного аналізу компонентів моделі &
			15.04.2024 & + \\
			\hline
			9.    & Проведення порівняння ефективності з існуючими рішеннями &
			15.04.2024 & + \\
			\hline
			10.    & Підготовка першої версії дипломної роботи &
			08.05.2024 & + \\
			\hline
			11.    & Оформлення пояснювальної записки &
			20.05.2024 & + \\
			\hline
	\end{longtable}

	\begin{tabularx}{\textwidth}{p{0.3\textwidth}p{0.3\textwidth}p{0.3\textwidth}}
		Студент & \_\_\_\_\_\_\_\_ & Дмитро СКОРОДЕНКО \\
		Керівник роботи & \_\_\_\_\_\_\_\_ & Сергій СИРОТА \\
	\end{tabularx}
\end{center}



% Створюємо анотацію
\abstractUkr

Дипломну роботу виконано на 50 аркушах,
вона містить 3 додатки та перелік посилань на використані джерела з 23 найменувань.
У роботі наведено 11 рисунків та 4 таблиці.

\paragraph{\textbf{Акутальність теми:}}
В сучасному світі технології розвиваються надзвичайно швидко. Швидкість цього розвитку можна виміряти
об'ємами даних, яким оперуюють люди. Так для 2000-х років було цілком достатньо мати дискети із максимальним вмістом
до 10-15 МБ. Станом на 2024 рік, існують різні накопичувачі від 16 ГБ до декількох десятків ТБ. Чому це важливо?
Для того щоб переносити велику кількість даних потрібно, щоб генерувалось ще більше даних. І це дійсно так, якщо
наприклад розглянути сучасні хостинги зображень, бази даних медзакладів, бази даних супутникових знімків і тд.
то всюди ми побачимо уже від сотень тисяч до сотень мільйонів зображень,
при чому швидкість появи нових зображень стрімко зростає. Основними причинами такого росту є: збільшення кількості людей
та стрімка цифровізація більшості аспектів людської життєдіяльності. Такий вибуховий ріст у швидкості
появи нових зображень створює проблему структуризації зображень. Для вирішення цієї проблеми можна присвоїти
кожному зображенню лейбли, які загально описують його вміст.
Без таких лейблів будь яка стуктура, яка містить у собі велику кількість зображень перетвориться
у звалище. Саме тому важливо мати швидкий та якісний метод для автоматичного маркування зображень.

\paragraph{\textbf{Мета дослідження:}}
Метою даної роботи є розробка ПЗ для маркування зображень (шпалерів робочого столу)
для покращення системи категоріального пошуку зображень (шпалерів робочого столу).

\paragraph{\textbf{Завдання дослідження:}}
Створення моделі, яка виконуватиме маркування шпалерів робочого столу на основі двох модальностей даних:
зображення та шумних тегів.

Для досягнення цієї мети було виконано наступні завдання:

\begin{itemize}
	\item Проведено аналіз існуючих рішень
	\item Виконано моделювання
	\item Проведено тренування нейронної мережі
	\item Проведено аналіз ефективності компонентів моделі
	\item Проведено порівняльний аналіз якісті і повноти опису розглянутої моделі
	відносно існуючих рішень на основі тестових метрик
	\item Проведено аналіз ілюстративних приклади роботи моделі
\end{itemize}

\paragraph{\textbf{Об'єкт дослідження:}}
Об'єктом дослідження є маркування зображень, та методи покращення маркування зображення.
Для порівняння ефективності маркування серед існуючих рішень було обрано моделі,
для яких обраховані тестові метрики для того ж датасету, який обрано в даній роботі.
До множини існуючих рішень належать: SR-CNN-RNN \cite{sr-cnn-rnn}, Resnet-SRN \cite{srn},
MS-CMA \cite{cma}, Query2Label \cite{q2l}, Resnet-CPSD \cite{cpsd} та ін.

\paragraph{\textbf{Предмет дослідження:}}
Предметом дослідження є множина шпалерів робочого столу в якості основної модальності даних,
та додаткова інформація (надані людьми шумні теги) в якості додаткової.

\paragraph{\textbf{Методи дослідження:}}
\begin{itemize}[*]
	\item Теорія системного аналізу
	\item Проектування систем Data Science / Deep learning
	\item Проектування інформаційних систем
	\item Обробка та аналіз зображень та тегів на основі методів глибинного навчання
	\item Теорія алгоритмів
	\item Аналіз даних та математична статистика
\end{itemize}

\paragraph{\textbf{Кінцевий результат:}}
Кінцевим результатом даної роботи є математичне та програмне забезпечення, архітектура моделі,
вагові коефіцієнти натренованої моделі та код програмного забезпечення, в якому реалізовано дану роботу.

\paragraph{\textbf{Ключові слова:}}
Маркування зображень, глибинне навчання, нейронні мережі, згорткові нейронні мережі,
багатошарові персептрони, композиція нейронних мереж.


\abstractEng

The thesis presented in 50 pages.
It contains 3 appendixes and bibliography of 23 references,
11 figures and 4 tables are given in the thesis.

\paragraph{\textbf{Topic relevance.}}
In modern world technologies are progressing with very high speed. The speed of this progress can be
measured by volume of stored data which people operate with. In this regard for the 2000s, it was
quite enough to have diskettes with the maximum volume of up to 10-15 MB. As of 2024, there are various
drives from 16GB to several tens of TB. Why is this important? In order to transfer large amounts of data,
even more data should be generated. And it really is, let's for example consider modern image hostings,
databases of medical institutions, databases of satelite images, etc. then everywhere we will see
from hundreds of thousands to hundreds of millions of images, and the rate of appearence of new images
is rapidly increasing. The main reasons for this growth are: an increase in the number of people globally and
the rapid digitalization of every aspect of our everyday lifes.
Such explosive growth in speed the appearance of new images creates a problem of image structuring.
To solve this problem, you can assign each image with labels that generally describe its content.
Without such labels, any structure that contains a large number of images will be like
a waste disposal site, where you can`t find anything.
That's why it's important to have a fast and quality method for automatic image labeling.

\paragraph{\textbf{Research goal:}}
The purpose of this work is to create deep learning model for automatic image labelling,
speccifically wallpapers, to improve categorical search using output labels.

\paragraph{\textbf{Research objectives:}}
Creating system, which will label images (wallpapers), given data of two modalities:
image and associated noisy tags.

To reach said objective the following tasks were completed:

\begin{itemize}
	\item Conducted analysis of existing solutions
	\item Modeled image labeling system
	\item Conducted model training
	\item Conducted analysis of performance gain from each component of composite system
	\item Conducted comparative analysis of model's labeling effectiveness
	with existing solutions
	\item Conducted analysis of illustrative examples of system's result
\end{itemize}

\paragraph{\textbf{Research object:}}
The object of research is image labeling and methods to imrove it.
To conduct comparative analysis to existing solution, only models which
are trained/tested on specific dataset were considered as 'existing solutions'.
To 'existing solutions' belong following models: SR-CNN-RNN \cite{sr-cnn-rnn}, Resnet-SRN \cite{srn},
MS-CMA \cite{cma}, Query2Label \cite{q2l}, Resnet-CPSD \cite{cpsd} etc.

\paragraph{\textbf{Research subject:}}
The subject of this work is subset of images which are called 'wallpapers'.
These are the images that you see as background image when you use your computer.
The main modality of date is image. Human provided tags would be additional modality.

\paragraph{\textbf{Research methods:}}
\begin{itemize}[*]
	\item System analysis
	\item Data Science / Deep learning
	\item Projecting of informational systems
	\item Processing and analysis of images and tags using methods of deep learning
	\item Theory of algorythms
	\item Data analysis and mathmatical statistics
\end{itemize}

\paragraph{\textbf{End result of research:}}
The end result of resarch is mathmatical and software implementation, architecure of model,
weights of trained models and source code of software which implements this work.

\paragraph{\textbf{Keywords:}}
Image labeling, deep learning, neural networks, convolutional neural networks,
multilayer perceptrons, composition of neural networks.


% створюємо зміст
\tableofcontents

\shortings

\begin{sortedlist}
	\sortitem{Модель - нейронна мережа}
	\sortitem{Задача класифікації - це задача, яка вирішує проблему приналежності чогось
	виключно до одного класу із довільного набору класів.}
	\sortitem{Задача маркування - це задача, яка вирішує проблему приналежності чогось
	до декількох класів із довільного набору класів.}
	\sortitem{DNN - Глибинна нейронна мережа (Deep Neural Network)}
	\sortitem{CNN - Згорткова нейронна мережа (Convolutional Neural Network)}
	\sortitem{RNN - Рекурсивна нейронна мережа (Recursive Neural Network)}
	\sortitem{ViT - Візуальні трансформери (Visual Transformers)}
	\sortitem{Тег (Tag) - шумна інформація надана користувачем у формі тексту}
	\sortitem{Лейбл (Label) - синонім слова ground truth для класифікації}
\end{sortedlist}


% створюємо перший розділ роботи
\uchapter{Вступ}

Задача класифікації - це одна із основних задач в аналізі зображень, вона полягає
у присвоєнні кожному зображенню один із класів. Таким чином дане формулювання накладає
обмеження - зображення містить тільки один об'єкт. Поява DNN \cite{dnn-cls}
та її подальший розвитком у CNN \cite{cnn-cls-1,cnn-cls-2} разом із створенням
великих датасетів як-от ImageNet \cite{deng2009imagenet} дало змогу вирішувати задачу
класифікації зображень значно швидше і якісніше ніж люди.

Зрозуміло, що зображення - це той тип даних, який у абсолютній більшості випадків містить більше одного об'єкта,
і відповідно більше одного класу для класифікації.
Для поглиблення опису існує задача маркування зображень (image labeling).
На відміну від класифікації, вона полягає у маркуванні зображення більше ніж одним класом.
Таким чином повнота опису зображення кратно зростає у порівннянні із звичайною класифікацією,
однак привносить декілька складних завдань.

\begin{enumerate}[1)]
	\item Наявність декількох класів у одного зображення створює можливість
описувати значно ширший спектр візуальної інформації: різні об'єкти, стилі, дії, і тд.
Це створює потребу у розгляді додаткових джерел інформації, так як одного лиш зображення вже недостатньо.
Поява великих хостингів зображень таких як Imgur, Flickr, та ін., де користувачі можуть
як завантажувати різноманітні зображення, так і додавати до них описову інформацію у вигляді
тегів / анотацій, дала змогу створити досить різноманітні датасети: ImageNet \cite{deng2009imagenet},
MS-COCO \cite{cocodataset}, NUS-WIDE \cite{nus-wide-civr09}, та ін. Також існують і інші види датасетів,
наприклад: рентгенівські знімки та додаткова інформація (інші аналізи пацієнта, історія хвороб ...),
супутникові знімки та додаткова інформація у вигляді метаданих, геолокацій тощо.
Таким чином задача якісного маркування зображення вже охоплює значно більший спектр даних ніж просто
зображення.

	\item Маркування зображень передбачає динамічну к-сть промаркованих класів,
так для опису зображенням із широким спектром понять необхідно 5-6 класів,
для зображення із простим вмістом - 2-3 класи.

	\item Маркування зображень потребує оцінки якості проведеного маркування. Оскільки будь який
датасет буде містити в собі дизбаланс класів в тій чи іншій мірі, важливо оцінювати маркування із
урахуванням цього.

	\item Маркування зображень значно складніша задача ніж класифікація і відповідно зростає
складність моделей. З однієї сторони складніша модель потенційно здатна покращити якість маркування,
з іншої - може сильно збільшити як час на виконання маркування, так і час затрачений на тренування системи.
До складних систем належать ті, які використовують трансформери та/або мають велику к-сть параметрів.
Отже, важливо обрати певний баланс відносно складності моделі.
\end{enumerate}

Все це робить задачу маркування зображення досить складною.


\chapter{Постановка задачі}

Метою даної дипломної роботи є розробка математичного та програмного забезпечення для
маркування зображень (шпалерів робочого столу) для покращення системи категоріального
пошуку зображень (шпалерів робочого столу).

До множини лейблів (цільових класів) віднесено 81 поняття із датасету NUS-WIDE \cite{nus-wide-civr09}.

До множини тегів (додаткових даних) віднесено 1000 найбільш частих тегів із $\approx 5000$ тегів у
датасеті NUS-WIDE \cite{nus-wide-civr09}.

Для досягнення цієї мети було виконано наступні завдання:

\begin{itemize}
	\item Проведено аналіз існуючих рішень
	\item Виконано моделювання
	\item Проведено тренування нейронної мережі
	\item Проведено аналіз ефективності компонентів моделі
	\item Проведено аналіз впливу максимальної кількості тегів на якість опису зображення
	\item Проведено порівняльний аналіз якісті і повноти опису розглянутої моделі
	відносно існуючих рішень на основі тестових метрик
	\item Проведено аналіз ілюстративних приклади роботи моделі
\end{itemize}


\chapter{Огляд існуючих рішень задачі маркування зображення}

Розглянемо ключові аспекти задачі маркування зображення.

\section{Базове рішення}

Базовим рішенням в задачі маркування зображення є аналіз основної модальності даних - зображення.
У абсолютній більшості існуючих робіт використовується CNN (Convolutional Neural Network).
Застосовуються різні архітекури даної моделі ResNet \cite{resnet}, AlexNet \cite{alexnet},
GoogleNet \cite{googlenet}, ResNext \cite{resnext}.

В якості базового рішення також можна використовувати ViT \cite{vit}. Дана модель використовує
трансформери, і аналізує зображення по частинам (patches).

Спільним між CNN та ViT є те, зазвичай їх рідко коли тренують з нуля, так як для цього необхідно багато ресурсів.
Саме тому використовують вже натреновані (pretrained) моделі на великому датасеті,
здебільшого ImageNet \cite{deng2009imagenet}.
Для адаптації моделі до обраного контексту така модель дотреновуєтсья (fine tune), замінюючи існуючий класифікатор.
Це працює завдяки тому, що всі архітектури сучасних CNN та ViT моделей містять десятки мільйонів параметрів,
даючи широку репрезентацію зображень. Для CNN - це ієрархічне представлення: перші шари репрезентують базові
особливості, а останні - більш специфичні особливості. Для ViT - це представлення, яке будується
на основі взаємозв'язків між різними частинками зображення за допомогою трансформерів.
Такі репрезентації зображень дозволяють адаптовувати модель під різні задачі після проведення підгонки (finetune).

Обидва підходи мають свої переваги та недоліки, і вибір між ними залежить від конкретної задачі,
доступних даних та обчислювальних ресурсів, так як ViT, попри всі свої переваги потребує в середньому
більше даних та ресурсів.

\section{Додаткова модальність даних}

Більш нові роботи також розглядають додаткові джерела інформації для підвищення якості та повноти
маркування зображень. Існує два основних підходи:

\begin{enumerate}
	\item \textit{Аналіз додаткової інформації.}
	Даний підхід аналізує додаткову до зображення інформацію.
	Це може бути як текстова інформація (теги / анотації) \cite{cnn-sinn,sr-cnn-rnn},
	так і метадані зображення \cite{cnn-neighbors,cnn-location}.
	Очевидним недоліком даного методу є потреба у цій додатковій інформації,
	яку можуть мати не всі зображення, а відсутність даної інформації
	знижує точність результуючого маркування.

	\item \textit{Аналіз цільових класів.}

	\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/resnet-cpsd-arch}
	\caption{
	Приклад архітектури моделі, яка використовує
	графове представлення цільових класів Resnet-CPSD \cite{cpsd}.
	}
	\label{figure:resnet-cpsd}
	\end{figure}

	На відміну від загальної інтерпретації класів для задачі маркування
	(коли кожен клас - це незалежна сутність), даний підхід аналізує зв'язки між цільовими класами,
	створючи нову модальність на основі набору цільових класів \cite{srn}.
	Більш новим та узагальненим підходом є технологія word2vec (або аналогічне рішення), яка дозволяє
	впорядкувати слова у певному векторному просторі таким чином, що їх просторове значення має
	прямий зв'язок із їх семантичним значенням. Наприклад модель Resnet-CPSD \cite{cpsd} використовує для аналізу класів
	граф, в якому вказуються класи (поняття) які часто знаходяться на одному зображенні
	(co-ocurrence; наприклад: риба, вода) та класи які рідко знаходяться
	на одному зображенні (dis-ocurrence; наприклад: риба, пустеля).
	Перевагою даного підходу є те, що йому не потрібні ніякі нові дані крім зображень та
	відповідних їм цільових класів, а нова модальність, яка репрезентує зв'язок між класами
	створюється під час тренування системи. Основним недоліком таких систем полягає у
	високій складності, і як наслідок - довше по часу тренування / розпізнавання.
\end{enumerate}

\clearpage

\section{Кількість лейблів}

Результатом роботи класифікаційної моделі є вектор ймовірностей, який репрезентує приналежність до класів.
Для задачі класифікації вибір результату на основі цього вектора очевидний - клас із найбільшою ймовірністю, однак
для задачі маркування все складніше.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/test-topk-144}
	\caption{
	Приклад адаптивної кількості лейблів,
	на основі роботи моделі на датасеті NUS-WIDE.
	'Truth' - правдиве маркування,
	'Top 5 pred' - ілюстрація вибору top $k$, при $k=5$,
	'Model pred' - приклад роботи моделі
	}
	\label{figure:test-topk}
\end{figure}

Більшість наведених вище робоіт розглядають задачу вибору к-сті лейблів як найкращі $k$ (top $k$) маркувань (\chaptername{ \ref{metrics}}),
де $k$ - наперед задана константа. Очевидно, що такий вибір к-сті класів не є оптимальним,
так як більш змістовні зображення будуть містити менше описової інформації і навпапки - менш змістовні будуть
містити лишню інформацію, яка до того ж може не мати нічого спільного із цим зображенням (\figurename{ \ref{figure:test-topk}})

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/cnn-rnn-lqp}
	\caption{
	Приклад застосування алгоритму "beam search", для
	пошуку найбільш оптимального маркування зображення
	на основі найвищої ймовріності, який
	реалізовано у системі CNN-RNN \cite{cnn-rnn}.
	}
	\label{figure:cnn-rnn-lqp}
\end{figure}

Один із підходів як-от CNN-RNN \cite{cnn-rnn},
використовує RNN для аналізу візуальних даних (visual features) та автоматично виконує як задачу маркування,
так і задачу динамічного вибору кількості лейблів, однак в силу особливості RNN є певні обмеження
накладенні на порядок кодування класів. При чому важливо відмітити, що вибір динамічної кількості лейблів
за допомогою RNN має суттєвий недолік - залежність від балансу цільових класів у даних.

Найновіші моделі \cite{q2l, cpsd, cma}, які розглядають зв'язок між цільовими класами, обирають
к-сть цільових класів на основі порогового значення threshold (\chaptername{ \ref{metrics}}).
Даний підхід є ефективним рішенням для вибору кількості лейблів, однак він релевантний
тільки для цього типу моделей, так як вектор ймовірностей, який отримується на виході
даної моделі досить сильно дискретизований, тобто для позитивного лейблу,
який маркуєтсья 1 ймовірність буде $\approx 0.7-0.9$,
а для негативного, тобто 0 ймовірність $\approx 0.1-0.3$.


\section{Висновки до розділу}

Було проведено огляд існуючих рішень задачі маркування зображення, відносно ключових аспектів рішення даної
задачі. Варто зазначити, що розглянуті рішення концентруються на загальному рішенні задачі маркуваня зображень,
і, в абсолютній більшості, не використовують додаткові дані.

В якості базового рішення між ViT та CNN варто використовувати CNN, так як вони є більш ефективними
з точки зору обчислень та інтерпретуються краще.

Для покращення якості маркування зображень буде залучено додаткову інформацію.
Так як дана робота націлена на маркування певної підмножини зображень, а саме: шпалерів робочого столу, - то
для покращення маркування будуть використовуватись надані користувачами теги. Варто зазначити, що
множина тегів має бути значно ширшою ніж множина лейблів (цільових класів) у співідношенні приблизно 10 до 1.
На відміну від аналізу цільових класів, даний підхід є значно простішим та досить ефективним,
хоч і потребує наявності додаткових тегів.

Розглянуті рішення націлені на розв'язок загальної задачі маркування зображення, тому в більшості випадків
використовується метод 'top 3'. Даний підхід цілком задовільний для обрахування тестових метрик, однак
є незадовільним для прикладного застосування (так як зображення будуть містити завжди 3 лейбли).
Інший метод розглядає порогове значення, яке підходить для вибору динамічної кількості лейблів, однак
містить значні недоліки у прикладному застосуванні. Таким чином доцільно використовувати метод 'top k'.


\chapter{Моделювання}

На основі проведного аналізу альтернатив, дана робота пропонує розглянути
модель, яка розглядає дві модальності даних: зображення та текстові теги.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{PNG/composite}
	\caption{Структура композитної нейронної мережі}
	\label{figure:composite}
\end{figure}

Структура даного рішення складається із чотирьох компонентів (\figurename{ \ref{figure:composite}}).


\section{Модель VCNN}

Модель VCNN (\figurename{ \ref{figure:vcnn}}) призначена для вивчення особливостей (features) із зображення.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{PNG/vcnn}
	\caption{Архітектура моделі VCNN}
	\label{figure:vcnn}
\end{figure}

Отримує на вхід піселі зображення $I$, у формі матриці розмірності $(B,C,W,H)$, де
$B$ - к-сть зображень у групі для тегування,
$C$ - к-сть каналів у зображеннях зазвичай 1 або 3, Grey або RGB відповідно,
$W,H$ - розмірність зображень.

За базове рішення використовуєтсья ResNext101\_32x8d \cite{resnext} (сучасна версія resnet),
так як у порівнянні із широко застосовуваною моделюю Resnet \cite{resnet} вона краще описує
зображення, та легше дотреновується при використанні натренованої на ImageNet \cite{deng2009imagenet} версії.

На виході даної моделі ми отримуємо вектор вірогідностей $vf$ (visual feature vector),
який вказує вірогідність маркування зображення класом $j$ на основі візуальної інформації.


\section{Модель MLP}

MLP (\figurename{ \ref{figure:mlp}}) - аналізує текстові особливості (text features) тегів до зображення.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{PNG/mlp}
	\caption{Архітектура моделі MLP}
	\label{figure:mlp}
\end{figure}

Теги до зображення $i$ репрезентуються як бінарний вектор $I = [1,0,1,0, ..., N]$,
де 1 - це наявність тегу, а $N$ - к-сть тегів.

Головна причина вибору звичайної MLP моделі для аналізу текстової інформації - це
те, що вхідна інформація - це шумні теги (наприклад: для фото кота - теги "Канада", "Кіт").
Важливим правилом щодо ефективності цього рішення є кількісне співвідношення між множиною
цільових класів та тегів, воно має бути приблизно 1 до 10.

На виході даної моделі ми отримуємо вектор $tf$ вірогідностей (text feature vector),
який вказує вірогідність маркування зображення класом $j$ на основі текстової інформації.


\section{Модель LP}

LP (\figurename{ \ref{figure:lp}}) - аналізує вектор вірогідності $v$,
який є композицією векторів $vf$ та $tf$: $v = [vf, tf]$.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{PNG/lp}
	\caption{Архітектура моделі LP}
	\label{figure:lp}
\end{figure}

На виході даної моделі ми отримуємо вектор вірогідностей, який комбінує інформацію отриману як із візуальної так і з
текстової інформації.


\section{Модель LQP}

Модель LQP (\figurename{ \ref{figure:lqp}}) аналізує кількість лейблів на основі вектору вірогідностей $v$,
який є композицією векторів $vf$ та $tf$: $v = [vf, tf]$.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{PNG/lqp}
	\caption{Архітектура моделі LQP}
	\label{figure:lqp}
\end{figure}

Існує два підходи до визначення к-сті за допомогою нейронних мереж: класифікація та регресія.
LQP - регресійна модель.

Оскільки регресійні моделі досить швидко перенавчаються (overfitting), то необхідно задіяти регуляризацію.
В даній роботі, в якості регуляризатора задіяні Dropout шари \cite{dropout}, із вірогідністю відкидання (dropout rate) $0.5$.

На виході даної моделі є число, яке вказує на кількість лейблів у зображенні.


\section{Процес тренування}

Модель складається із декількох компонентів, що створює декілька проблемних місць під час тренування:
досить багато параметрів, дві різні цільові функції, проблема затухаючого градієнта, -
тому тренування відбуваєтсья у декілька стадій, у якому кожна із моделей тренується окремо
(деякі з них можна тренувати синхронно).


\subsection{Цільові функції}

Для початку варто розглянути цільові функції (функція втрат, loss function).
Дані функції є базовим компонентом глибинного навчання.

В даній роботі використовуютсья дві функції: BCEWithLogitsLoss та MSELoss.

\paragraph{\textbf{BCEWithLogitsLoss}\\}

Для тренування класифікаційних моделей (VCNN, MLP, LP) вихідні логіти $z_{ij}$
для групи (batch) зображень $I_N$ при $i = 1...N$, $j = 1...C$,
де $N$ - кількість зображень в групі, $C$ - кількість цільових класів,
цільова функція має вигляд:

\begin{equation}
\mathcal{L}_{cls} = \frac{1}{NC} \sum_{i}^{N} \sum_{j}^{C}
y_{ij} \cdot ln(\sigma(z_{ij})) + (1 - y_{ij}) \cdot ln(1 - \sigma(z_{ij}))
\end{equation}

, де $y_{ij} = 1$ якщо зображення $i$ анотоване класом $j$, інакше - $y_{ij} = 0$,
а $\sigma(\cdot)$ - це сигмоїдальна активаційна функція

\paragraph{\textbf{MSELoss}\\}

Для тренування регресійної моделі LQP вихідні логіти $z_i$
для групи (batch) зображень $I_N$ при $i = 1...N$,
де $N$ - кількість зображень в групі,
цільова функція має вигляд:

\begin{equation}
\mathcal{L}_{reg} = \frac{1}{N} \sum_{i}^{N}
(y_i - z_i)^2
\end{equation}

, де $y_i$ - це кількість лейблів для зображення $I_i$.


\subsection{Тренування VCNN}

Тренування моделі ResNext \cite{resnext} з нуля є досить складною задачою (дана модель має $\approx$ 80M параметрів),
адже для цього потрібні значні обчислювальні потужності.

Саме тому вироистовується натренована модель із адаптованим класифікатором (visual feature extractor) (\figurename{ \ref{figure:composite}}), яка підганяється (finetuned) на обраному датасеті.

Існує два підходи для підгонки:

\begin{enumerate}[1)]
	\item Підгонка всієї моделі (finetuning):
	всі шари моделі підганяються (дотреновуються) з низькою швидкістю навчання (learning rate).
	Даний підхід вимагає великої обчислювальної потужності, однак надає високу точність та
	досить таки швидко тренується (в порівнянні із тренуванням з нуля).

	\item Підгонка класифікатора (transfer learning):
	відбуваєтсья тренування тільки класифікатора, фіксуючи всі інші параметри моделі.
	Даний підхід значно пришвидшує тренування в обмін на певну деградацію точності в порівнянні із 1-им варіантом.
\end{enumerate}

В даній роботі використовується 1 варіант підгонки, так як він надає вищу точність.


\subsection{Тренування MLP}

Дана модель є звичайним багатошаровим персептроном, тому її
можна без проблем натренувати з нуля.

Також цю модель можна тренувати паралельно із VCNN.


\subsection{Тренування LP}

Дана модель призначена для обрахування вірогідностей на основі вектору $f = [vf, tf]$, оскільки вона
складається із одного шару то її тренування також очевидне.

Також цю модель можна тренувати паралельно із LQP.


\subsection{Тренування LQP}

Дана модель є регресійним багатошаровим персептронои, її тренування також є очевидним,
однак варто нормалізувати вхідну к-сть лейблів, так як це пришвдшить та/або покращить збіжність моделі.

Під час тренування використовуються шари Dropout, так як дана модель дуже швидко перенавчається.
В даній роботі вірогідність відкидання (dropout rate) 0.5.

Також цю модель можна тренувати паралельно із LP.


\section{Процес тестування}

\subsection{Тестування класифікаційних моделей (VCNN, MLP, LP)}

Кожна із даних моделей обраховує вектор ймовірностей $P$,
для тестування необхідно перевести вектор ймовірностей (наприклад: $P = [0.9, 0.6, 0.1, 0.4, 0.6]$)
у вигляд маркування (наприклад: $M = [1,1,0,0,1]$). Дане перетворення називаєтсья індикаторною функцією.

\paragraph{Розглянемо два основних види індикаторної функції:}

\begin{enumerate}[1)]
	\item Порогове значення (threshold):
	для вектору ймовірностей $P$ та порогу $\alpha$ - вектор маркувань обраховується наступним чином:
	якщо $y_i > \alpha$, то маркуємо $1$, інакше $0$.
	Наприклад при $\alpha = 0.5$: $[0.9, 0.6, 0.1, 0.4, 0.6] \to [1,1,0,0,1]$.

	\item Найкращі $k$ (top $k$):
	для вектору ймовірностей $P$ та числа $k$ - вектор маркувань обраховується наступним чином:
	маркуємо $1$ найкращі $k$ ймовірностей, інакше $0$.
	Наприклад при $k = 4$: $[0.9, 0.6, 0.1, 0.4, 0.6] \to [1,1,0,1,1]$.
\end{enumerate}

Оскільки дані моделі не передбачають передбачення кількості лейблів,
то для тренування даних моделей використовується метод top $k$, при чому
$k = 3$.

\label{dynk}

Тобто для зображення $I$,
із маркуванням $Y = [1,0,0,0,1]$,
і вектором ймовірностей $P = [0.8,0.9,0.1,0.5,0.2]$
та результуючим вектором маркувань $M$:
$k = 3$, перетворення $P \to M \equiv [0.8,0.9,0.1,0.3,0.2] \to [1,1,0,1,0]$


\subsection{Тестування композитної моделі}

Для тестування композитної моделі (\figurename{ \ref{figure:composite}})
необхідно обрахувати результуючі значення для моделей LP та LQP, і обрати
top $k$ лейблів LP, де $k$ - це передбачення LQP.


\section{Висновки до розділу}

Було проведено опис архітектури композитної нейронної мережі. Результуюча модель
містить 4 компоненти (нейронні мережі), які виконують маркування зображення
на основі даних із двома модальностями: зображення та тегів.

Також було наведено детальний опис процесу тренування та тестування, набору цільових функцій, які використовуються
для тренування класифікаційни та регресійної моделей.


\chapter{Експерименти}

\section{Датасет}

Один із найбільш часто використовуваних датасетів для тестування моделей маркування зображень - NUS-WIDE \cite{nus-wide-civr09},
він складаєтсья із 269,655 зображень, 81 лейблу, та $\approx$ 5000 тегів в якості сторонньої текстової інформації.
Для проведення тренування/тестування використовується розподіл, надведений разом із
датасетом, так як він є збалансовний настільки, наскільки це можливо (\figurename{ \ref{figure:nus-wide-dist}}).

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/nus-wide-label-dist}
	\caption{Розподіл лейблів у тренувальному/тестовому датасеті}
	\label{figure:nus-wide-dist}
\end{figure}

З наведеного графіку можна зробити висновок, що він містить значний дизбаланс відносно кількості класів,
так як він був зібраний на основі реальних даних, якими користувались люди, із вебсайту 'Flickr'.

Важливо відмітити, що даний датасет містить посиланя на зображення на ресурсі 'Flickr', і деякої частина цих
зображень вже там немає.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/nus-wide-tag-dist}
	\caption{Розподіл тегів у тренувальному/тестовому датасеті}
	\label{figure:nus-wide-dist}
\end{figure}

Також буде використано тільки 1000 найбільш частих тегів з $\approx$ 5000,
при чому зображення, які не містять жодного тега відфільтровано.

\clearpage

\subsection{Множина цільових класів}

Датасет NUS-WIDE \cite{nus-wide-civr09} містить 81 цільовий клас.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{PNG/nus-wide-label-cloudmap}
	\caption{
	Візуалізація цільових класів у датасеті.
	Класи із більшою частотою мають більший шрифт тексту
	та темніший колір.
	}
	\label{figure:nus-wide-label-cloudmap}
\end{figure}

Множина цільових класів містить значний дизбаланс відносно частоти.

\clearpage

\subsection{Числові характеристики датасету}

\begin{center}
\begin{tabular}{|c|c|c|}
		\hline
           & Тренування & Тестування \\
        \hline
        Кількість зобаржень & 121962  & 81636 \\
        Середня к-сть лейблів & 2.42  & 2.43 \\
        Медіана к-сть лейблів & 2  & 2 \\
        Мінімальна к-сть лейблів & 1  & 1 \\
        Максимальна к-сть лейблів & 12  & 13 \\
        Середня к-сть тегів & 6.27  & 6.26 \\
        Медіана к-сть тегів & 5  & 5 \\
        Мінімальна к-сть тегів & 1  & 1 \\
        Максимальна к-сть тегів & 131  & 125 \\
        \hline
\end{tabular}
\captionof{table}{Характеристики тренувальної/тестової вибірок}
\end{center}

З наведеної таблиці варто відзначити характеристики, що стосуються тегів. Так як теги - це
стороння інформація, враховуючи що медіана = 5, то варто розглянути який впилив несе менша кількість
тегів для маркування, так як зазвичай при завантажені люди додають власноруч приблизно 3 теги.
Тому в пода'льшому буде розглянуто вплив тегів, при виборі фіксованої максимальної кількості тегів.

\clearpage


\section{Тестові метрики}
\label{metrics}

Для оцінки точності будуть використовуватись метрики, які є загально вживаними для оцінки
задачі маркування зображень (multi-label image annotation).

\begin{equation}
\begin{aligned}
\textnormal{С-P} &= \frac{1}{C} \sum_{j=1}^C \frac{NI^c_j}{NI^p_j} & \textnormal{O-P} &= \frac{\Sigma^N_{i=1} NL^c_i}{\Sigma^N_{i=1} NL^p_i} \\
\textnormal{C-R} &= \frac{1}{C} \sum_{j=1}^C \frac{NI^c_j}{NI^g_j} & \textnormal{O-R} &= \frac{\Sigma^N_{i=1} NL^c_i}{\Sigma^N_{i=1} NL^g_i} \\
\textnormal{C-F1} &= \frac{2 \cdot \textnormal{C-P} \cdot \textnormal{C-R}}{\textnormal{C-P} + \textnormal{C-R}} & \textnormal{O-F1} &= \frac{2 \cdot \textnormal{O-P} \cdot \textnormal{O-R}}{\textnormal{O-P} + \textnormal{O-R}} \\
\end{aligned}
\end{equation}

,де \begin{itemize}[*]
        \item $C$ - к-сть класів
        \item $N$ - к-сть тестових зображень
        \item $NI^c_j$ - к-сть зображень які коректно промарковано як клас $j$
        \item $NI^g_j$ - к-сть зображень які мають клас $j$
        \item $NI^p_j$ - к-сть зображень які промарковано як клас $j$
        \item $NL^c_i$ - к-сть коректно промаркованих лейблів для зображення $i$
        \item $NL^g_i$ - к-сть лейблів які має зображення $i$
        \item $NL^p_i$ - к-сть промаркованих лейблів для зображення $i$
\end{itemize}

Варто відзначити, що дані метрики є зміщеними (biased),
при чому по-класові метрики (C) зміщені в сторону рідкісних класів,
а загальні метрики (O) - в сторону частих класів \cite{cnn-labeling}.

\clearpage

Для того щоб отримати унфіормене представлення про ефективність моделі
буде використовуватись наступна метрика,
яка бере до уваги як C-F1 так і O-F1, що полегшує інтерпретацію результатів:

\begin{equation}
\text{H-F1} = \frac{2 \cdot \text{C-F1} \cdot \text{O-F1}}{\text{C-F1} + \text{O-F1}}
\end{equation}


\clearpage


\section{Тренування}

Для програмної реалізації запропонованої моделі було використано PyTorch.

Оскільки в даній роботі, використовується модель ResNext \cite{resnext} натренована
на датасеті ImageNet \cite{deng2009imagenet}, то для вхідних зображень потрібно
застосувати певне перетворення:

\begin{enumerate}[1)]
	\item Зміна розміру (Resize) $232 \times 232$,
	використовуючи білінійну інтерполяцію
	\item Центральний кроп (Central crop) $224 \times 224$
	\item Зміна масшатбу (Rescale) [0,1]
	\item Нормалізація на основі статистичних величин ImageNet \cite{deng2009imagenet}.
	А саме: mean = [0.485, 0.456, 0.406] та std = [0.229, 0.224, 0.225]
\end{enumerate}

Дане перетворення доступно у біблоітеці PyTorch.


\subsection{Параметри навчання}

Класифікаційні моделі VCNN та MLP навчались із
швидкістю навання (learning rate) 0.001, а LP - зі швидкістю 0.01.
Також для начання цих трьох моделей використовувався контроллер швикдості навчання
(learning rate scheduler), який множив швидкість навчання на 0.5, досягаючи
5-ої та 10-ої епохи.

Регресійна модель LQP навчалась із сталою швидкістю навчання (learning rate) 0.0005.

Для всіх навчання всіх вище згаданих моделей використовувався оптимізатор
AdamW, із параметром l1 регуляризації (weight decay) 0.0003.

Розмір групи (batch size) 32.

Також варто відзначити, що в даній роботі епоха - це 20\% від усіх даних,
при чому після кожної епохи дані перемішуються (shuffle), отримаючи
нові 20\% даних.


\subsection{Процес навчання}

Для тренування було використано графічний процесор 'Nvidia L4'.
Для тренування всіх елементів моделі знадобилось $\approx$ 3 години.

Для оптимізації процесу тренування було застосовано техніку mixed precision,
яка використовує f16 замість f32, під час певних етапів тренування \cite{mixed-precision}.

\begin{figure}[h]
\centering
	\subcaptionbox{Навчання VCNN}
		{\includegraphics[width=0.495\linewidth]{PNG/vcnn-train}}
	\subcaptionbox{Навчання MLP}
		{\includegraphics[width=0.495\linewidth]{PNG/mlp-train}}
	\subcaptionbox{Навчання LP}
		{\includegraphics[width=0.495\linewidth]{PNG/lp-train}}
	\subcaptionbox{Навчання LQP}
		{\includegraphics[width=0.495\linewidth]{PNG/lqp-train}}
\caption{Процес навчання моделей}
\end{figure}

З наведених вище графіків можна прийти до висновку, що кожна із 4-ох компонентів моделі
успішно завершила процес навчання (збіглась).


\section{Висновки до розділу}

Було проведено детальний огляд обраного датасету:

\begin{itemize}[*]
	\item Тренувальна/тестова вибірки містять 121962 та 81636 зображень відповідно
	\item Всі зображення, які не містять жодного тегу було відфільтровано
	\item Множина лейблів (цільових класів) містить 81 унікальне значення
	\item В якості додаткової інформації використовуються теги, які містять 1000 унікальних значень
	\item цільові класи містять значний дизбаланс відносно частот
\end{itemize}


Детально наведено тестові метрики, дані метрики використовуються в абсолютній більшості робіт,
що дає можливість проводити детальний порівняльний аналіз.

Наведено деталі для перетворення даних, для роботи мережі. Підібрано оптимальні значення для
проведення навчання та графіки, які описують сам процес навчання.


\chapter{Аналіз результатів}

\section{Аналіз компонентів моделі}

\begin{center}
\resizebox{\textwidth}{!}{\begin{tabular}{|l|c|c|ccc|ccc|c|}
		\hline
		Модель & Індикаторна ф-ція (\ref{dynk}) & Модальність & C-P & C-R & C-F1 & O-P & O-R & O-F1 & H-F1 \\
        \hline
        Композитна  & top k & Зображення+теги & 72.49 & 59.51 & 65.36 & 76.53 & 74.41 & 75.46 & 70.04 \\
        VCNN+MLP+LP & top 3 & Зображення+теги & 60.51 & 61.28 & 60.89 & 67.87 & 71.52 & 63.98 & 62.40 \\
        VCNN+LQP    & top k & Зображення  & 64.62 & 37.61 & 47.54 & 77.07 & 59.01 & 66.84 & 55.56 \\
		VCNN        & top 3 & Зображення  & 44.48 & 53.32 & 48.50 & 55.44 & 68.52 & 61.29 & 54.15 \\
        \hline
\end{tabular}}
\captionof{table}{Порівняння компонентів моделі}
\end{center}

Результуюча композитна модель показала значно кращий результат ніж базове рішення (VCNN).

\paragraph{\textbf{Додаткова модальність (MLP+LP)}\\}

Додавання додаткової модальності у вигляді тегів внесло значний вклад
у підвищення якості маркування.
Порівнюючи відповідні метрики H-F1 для моделей VCNN та VCNN+MLP+LP, можна
побачити приріст на $8.25\%$. При чому варто відзначити, що цей ріст в основному
забезпечений приростом метрики C-F1, яка є зміщеною в сторону більш рідкісних класів.
Варто відзначити, що це працює завдяки тому що зазвичай теги надані користувачами відмічають
досить рідкісні поняття, які на відміну від частих тегів (небо, сонце, людина, вода і тд.) складно
розпізнати маючи одне лиш зображення.

\paragraph{\textbf{Передбачення кількості лейблів (LQP)}\\}

При використанні компоненту LQP кількість лейблів обирається за принципом 'top k', а не 'top 3' (\ref{dynk}).
Це очевидним чином підвищує точність фінального  маркування, адже деякі зображення можуть мати більше трьох лейблів,
інші - менше трьох. Порівнюючи вплив компоненти LQP для базового рішення (VCNN) та композитної моделі (VCNN+MLP+LP+LQP)
можна зробити припущення, що VCNN аналізує загальні поняття на зображенні, а враховуючи дизбаланс класів у датасеті,
використання принципу 'top k' збільшує точність (precision), сильно жертвуючи по-класовим охопленням (C-R), і,
як наслідок, не сильно збільшуючи величину головної метрики H-F1. На практиці це виливалось у те, абсолютна більшість
зображень маркувалась частими лейблами (людина, вода, небо і тд.), а рідкісні теги - ігнорувались.
Натомість у композитній моделі вищезгаданий принцип чудово проявив себе.
Згідно із тестовими метриками покращення становить $7.64\%$.


\section{Аналіз впливу додаткової інформації}

При завнтажені зображення на певний ресурс люди можуть вказати додаткову тегову інформацію
для покращення роботи автоматичного маркування, однак зазвичай вони вказують до 4-5 тегів,
а оскільки медіана кількості тегів у датасеті становить 5, то варто роозглянути вплив кількості
тегів на процес тегування більш детально.

\begin{center}
\resizebox{0.8\textwidth}{!}{\begin{tabular}{|c|ccc|ccc|c|}
		\hline
		Максимальна кількість тегів & C-P & C-R & C-F1 & O-P & O-R & O-F1 & H-F1 \\
		\hline
        0 & 44.48 & 53.32 & 48.50 & 55.44 & 68.52 & 61.29 & 54.15 \\
        1 & 66.42 & 37.28 & 47.75 & 74.80 & 66.78 & 70.56 & 56.96 \\
        2 & 70.20 & 43.00 & 53.33 & 75.50 & 68.75 & 71.97 & 61.26 \\
        3 & 71.06 & 46.97 & 56.55 & 75.70 & 69.85 & 72.66 & 63.60 \\
        4 & 71.11 & 49.80 & 58.57 & 75.95 & 71.00 & 73.39 & 65.15 \\
        5 & 71.99 & 52.62 & 60.80 & 76.19 & 71.95 & 74.01 & 66.76 \\
        6 & 71.92 & 53.37 & 61.49 & 76.25 & 72.44 & 74.30 & 67.29 \\
        7 & 71.86 & 54.65 & 62.08 & 76.35 & 72.85 & 74.56 & 67.75 \\
        8 & 72.25 & 56.03 & 63.12 & 76.49 & 73.26 & 74.84 & 68.48 \\
        9 & 72.07 & 56.55 & 63.37 & 76.57 & 73.62 & 75.07 & 68.73 \\
        10 & 72.33 & 57.13 & 63.84 & 76.59 & 73.83 & 75.18 & 69.05 \\
        - & 72.49 & 59.51 & 65.36 & 76.53 & 74.41 & 75.46 & 70.04 \\
        \hline
\end{tabular}}
\captionof{table}{Порівняння впливу кількості тегів на маркування}
\end{center}

З наведеної таблиці можна зробити висновок, що між якістю маркування та кількістю тегів
є пряма залежність. В середньому приріст точності відносно метрики H-F1 становить $1-2\%$.
Також варто відзначити, що після проходження медіани (5) приріст спадає
до менше ніж $0.5\%$.

Таким чином для того щоб досягати оптимальної якості із найменшою кількістю додаткових тегів потрібно розглядати
від 2 до 5 тегів.


\section{Порівнняня з існуючими рішеннями}

\begin{center}
\resizebox{\textwidth}{!}{\begin{tabular}{|l|c|c|ccc|ccc|c|}
	\hline
	Модель & Індикаторна ф-ція (\ref{dynk}) & Модальність & C-P & C-R & C-F1 & O-P & O-R & O-F1 & H-F1 \\
	\hline
	Композитна  & top k & Зображення+теги & 72.49 & 59.51 & 65.36 & 76.53 & 74.41 & 75.56 & 70.04 \\
	\hline
	Query2Label \cite{q2l} & threshold $\alpha$ & Зображення (+аналіз класів) & - & - & 67.60 & - & - & 76.3 & 71.69 \\
	SR-CNN-RNN \cite{sr-cnn-rnn} & top 3 & Зображення+теги & 71.73 & 61.73 & 66.36 & 77.41 & 76.88 & 77.15 & 71.35 \\
	Resnet-CPSD \cite{cpsd} & threshold $\alpha$ & Зображення (+аналіз класів) & - & - & 64.00 & - & - & 75.30 & 69.19 \\
	MS-CMA \cite{cma} & threshold $\alpha$ & Зображення (+аналіз класів) & - & - & 60.50 & - & - & 73.80 & 66.49 \\
	Resnet-SRN \cite{srn} & threshold 0.5 & Зображення (+аналіз класів) & 65.20 & 55.80 & 58.50 & 75.50 & 71.50 & 73.40 & 65.10 \\
	SINN \cite{cnn-sinn}  & top 3 & Зображення+теги & 58.30 & 60.63 & 59.44 & 57.05 & 79.12 & 66.29 & 62.68 \\
	TagNeighbour \cite{cnn-neighbors}  & top 3 & Зображення+метадані & 54.74 & 57.30 & 55.99 & 53.46 & 75.10 & 62.46 & 59.05 \\
	CNN+Logistic \cite{cnn-sinn}  & top 3 & Зображення  & 45.60 & 45.03 & 45.31 & 51.32 & 70.77 & 59.50 & 51.44 \\
	CNN-RNN \cite{cnn-rnn}  & top 3 & Зображення  & 40.50 & 30.40 & 34.70 & 49.9 & 61.70 & 55.20 & 42.61 \\
	CNN+WARP \cite{cnn-labeling}  & top 3 & Зображення  & 31.65 & 35.60 & 33.51 & 48.59 & 60.49 & 53.89 & 41.32 \\
	CNN+Softmax \cite{cnn-labeling}  & top 3 & Зображення  & 31.68 & 31.22 & 31.45 & 47.82 & 59.52 & 53.03 & 39.48 \\
	\hline
\end{tabular}}
\label{table:models-metrics}
\captionof{table}{Порівняння результуючих метрик для різних моделей на датасеті NUS-WIDE}
\end{center}


\paragraph{\textbf{Точність запропонованого рішення}}
Композитна модель (VCNN+MLP+LP+LQP) продемонструвала високу якість маркування на тестових метриках у порівнянні
із розглянутими альтернативними рішеннями. Згідно із метрикою H-F1 запропоноване рішення є третім.

\paragraph{\textbf{Модальність даних}}
Задача маркування зображень розглядає зображення як основну модальність, однак додавання модальності,
очікувано, покращує результати маркування. Це підтверджують метрики наведені в \tablename{ \ref{table:models-metrics}}.
Серед розглянутих рішень є 3 варіанти модальності даних з якимим працюють нейронні мережі.
Найменш ефективним, як і очікувалось, виявились моделі які аналізують виключно зображення.
Введення інших двох видів додаткових модальностей: теги, аналіз класів, - надають значно кращі результати.
Варто відзначити, - аналіз класів (найкраще імплементовано в: Query2Label \cite{q2l}, Resnet-CPSD
\cite{cpsd} та MS-CMA \cite{cma}) не потребує ніяких додактових даних окрім зображення,
що є вагомою конкурентною перевагою, враховуючи незначну відміність в точності моделей.

\paragraph{\textbf{Індикаторна функція}}
Для оцінки ефективності запропонованої індикаторної функції 'top k', варто ізолювати вплив саме цієї фнкції.
Для ціього розглянемо існуючі моделі, які працюють із тією ж модальністю даних. Найкращою із таких моделей є
SINN \cite{cnn-sinn}. Використання моделі LQP, яка передбачає роботу із динамічною кількістю лейблів при маркуванні
(top k) значено підвищує якість. Згідно із наведеними метриками покращення складає
$7.36\%$ (\tablename{ \ref{table:models-metrics}}), що є вагомим приростом.


\clearpage

\section{Демонстративні приклади}

З тестового датасету випадковим чином обрано декілька зображень, для демонстрації роботи моделі:

\begin{figure}[h]
\centering
	\subcaptionbox{}
		{\includegraphics[width=0.495\linewidth]{PNG/showcase-1-20}}
		\label{figure:showcase-1}
	\subcaptionbox{}
		{\includegraphics[width=0.495\linewidth]{PNG/showcase-2-30}}
		\label{figure:showcase-2}
	\subcaptionbox{}
		{\includegraphics[width=0.495\linewidth]{PNG/showcase-3-40}}
 	\subcaptionbox{}
 		{\includegraphics[width=0.495\linewidth]{PNG/showcase-4-70}}
\caption{Демонстративні приклади}
\end{figure}

Задамо умовне позначення "а::1", що означає демонстративний приклад "а", перше зображення зверху,
"в::2" - приклад "в", друге зображення зверху і тд.

Серед наведених прикладів можна розглянути кілька цікавих моментів, які не відображають тестові метрики:

\begin{itemize}[*]
	\item Іноді модель передбачає маркування, якого немає у датасеті, однак присутнє на зображені.
	Наприклад: [а::3,а::4,б::1,б::3,б::4,в::1,в::2,г::2,г::3].
	\item Існують випадки коли модель відмічає поняття, які не можуть бути присутніми на одному зображенні.
	Це є прямим наслідком того, що наша модель розглядає цільові класи як незалежі сутності.
	Наприклад: lake та ocean як-от в прикладі 'в::3'.
	\item Іноді передбачення моделі відсікають неіснуючі поняття та маркують зображення краще ніж це
	було зроблено в датасеті. Так для зображення 'б::3' на якому зображено якусь рослину датасет
	вказує що це: 'buildings, clouds'; а модель - 'flowers'.
\end{itemize}

Окрім наведених вище особливих випадків, іноді модель, звичайно, помиляється. Однак у наведених
прикладах немає значних помилок у маркуванні.


\section{Висновки до розділу}

Проведено аналіз компонентів моделі та доведено ефективність кожного із них.

Розглянуто вплив максимальної кількості тегів на якість маркування, і визначено,
що перші декілька максимальних значень (від 1 до 5) вносять значне покращення на якість маркування,
однак після проходження медіани (5 тегів) кількості тегів,
відбувається деградація цього ефекту, і приріст стає незначним.

У порівнянні із існуючими рішеннями модель показала себе чудово, однак варто зазначити, що
найкращі рішення такі як Query2Label \cite{q2l}, Resnet-CPSD \cite{cpsd} та ін. досягають
співставної точності навіть без додаткової інформації, що є суттєвою перевагою.

Також було розглянуто декілька демонстративних прикладів роботи моделі.


% створюємо Висновки
\conclusions

В даній роботі було розглянуто композитну модель, для маркування зображень (шпалерів робочого столу)
проведено оцінювання її точності на тестових метриках.

Розглянута модель показала хороший результат у порівнянні із існуючими альтернативними рішеннями.

До переваг розглянутого рішення належать:

\begin{itemize}[+]
	\item Висока точність
	\item Невелика кількість параметрів ($\approx 95\%$ параметрів має модель для аналізу зображень)
	\item Висока швидкість тренування
\end{itemize}

Недоліками є:

\begin{itemize}[-]
	\item Неможливість тренування моделі в один етап (end-to-end)
	\item Необхідність використання додаткових даних (тегів) для
	отримання високої якості опису зображення
\end{itemize}

Також було розглянуто вплив кількості тегів у додатковій інформації на якість маркування, та визначено
опитмальну кількість тегів для ефективної роботи даної моделі, що становить від 2 до 5 тегів.

В подальшому варто розглянути ефективність даної моделі на інших датасетах (наприклад MSCOCO \cite{cocodataset}).
також варто розглянути і методи для аналізу цільових класів, так як незважаючи на
значне ускладнення фінальної моделі це надає досить високий приріст до точності маркування.

Результуюча композитна модель збережена у форматі safetensors.


\printbibliography


\append{Лістинг програм}

\setminted{fontsize=\footnotesize}

\captionof{listing}{data.py - Класи для підготовки та паралеізації завнантаження даних}
\inputminted{python}{../data.py}

\captionof{listing}{models/utils.py - утиліти для вирішення певних проміжних задач}
\inputminted{python}{../models/utils.py}

\captionof{listing}{models/vcnn.py - модель VCNN}
\inputminted{python}{../models/vcnn.py}

\captionof{listing}{models/mlp.py - модель MLP}
\inputminted{python}{../models/mlp.py}

\captionof{listing}{models/lp.py - модель LP}
\inputminted{python}{../models/lp.py}

\captionof{listing}{models/lqp.py - модель LQP}
\inputminted{python}{../models/lqp.py}

\captionof{listing}{models/compose.py - композитна модель}
\inputminted{python}{../models/compose.py}

\captionof{listing}{scripts/1ktags.py - скрипт для підготовки лейблів/тегів}
\inputminted{python}{../scripts/1ktags.py}

\captionof{listing}{scripts/nuswide2ndjson.py - скрипт для підготовки датасету}
\inputminted{python}{../scripts/nuswide2ndjson.py}

\captionof{listing}{scripts/train/vcnn.py - скрипт для тренування VCNN}
\inputminted{python}{../scripts/train/vcnn.py}

\captionof{listing}{scripts/train/mlp.py - скрипт для тренування MLP}
\inputminted{python}{../scripts/train/mlp.py}

\captionof{listing}{scripts/train/lp.py - скрипт для тренування LP}
\inputminted{python}{../scripts/train/lp.py}

\captionof{listing}{scripts/train/lqp.py - скрипт для тренування LQP}
\inputminted{python}{../scripts/train/lqp.py}

\captionof{listing}{scripts/compose2safe.py - скрипт для конвертації вагових коефіцієнтів у результуючу модель}
\inputminted{python}{../scripts/compose2safe.py}

\captionof{listing}{scripts/test.py - скрипт для тестування роботи композитної моделі}
\inputminted{python}{../scripts/test.py}

\append{Додаткові приклади}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-100}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-125}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-150}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-175}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-200}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-225}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-250}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-275}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-300}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-325}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-350}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-375}
	\caption{}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/showcase-400}
	\caption{}
\end{figure}

\append{Ілюстративний матеріал}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-1}
	\caption{Слайд 1}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-2}
	\caption{Слайд 2}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-3}
	\caption{Слайд 3}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-4}
	\caption{Слайд 4}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-5}
	\caption{Слайд 5}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-6}
	\caption{Слайд 6}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-7}
	\caption{Слайд 7}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-8}
	\caption{Слайд 8}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-9}
	\caption{Слайд 9}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-10}
	\caption{Слайд 10}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-11}
	\caption{Слайд 11}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-12}
	\caption{Слайд 12}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-13}
	\caption{Слайд 13}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-14}
	\caption{Слайд 14}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-15}
	\caption{Слайд 15}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-16}
	\caption{Слайд 16}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-17}
	\caption{Слайд 17}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-18}
	\caption{Слайд 18}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-19}
	\caption{Слайд 19}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-20}
	\caption{Слайд 20}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-21}
	\caption{Слайд 21}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-22}
	\caption{Слайд 22}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-23}
	\caption{Слайд 23}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-24}
	\caption{Слайд 24}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-25}
	\caption{Слайд 25}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-26}
	\caption{Слайд 26}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-27}
	\caption{Слайд 27}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-28}
	\caption{Слайд 28}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-29}
	\caption{Слайд 29}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.9\textwidth]{PNG/present/present-30}
	\caption{Слайд 30}
\end{figure}

\end{document}
