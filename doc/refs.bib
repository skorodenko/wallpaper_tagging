@article{dnn-cls,
  author = {Dan Cire≈üan and Ueli Meier and Juergen Schmidhuber},
  title = {Multi-column Deep Neural Networks for Image Classification},
  year = {2012},
  archivePrefix = {arXiv},
  eprint = {1202.2745},
  howpublished = {CVPR 2012, p. 3642-3649},
}

@misc{cnn-cls-1,
  author = {Karen Simonyan and Andrew Zisserman},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year = {2014},
  eprint = {arXiv:1409.1556},
}

@misc{cnn-cls-2,
  author = {Keiron O'Shea and Ryan Nash},
  title = {An Introduction to Convolutional Neural Networks},
  year = {2015},
  eprint = {arXiv:1511.08458},
}

@misc{cnn-semantic-1,
  author = {Hexiang Hu and Guang-Tong Zhou and Zhiwei Deng and Zicheng Liao and Greg Mori},
  title = {Learning Structured Inference Neural Networks with Label Relations},
  year = {2016},
  howpublished = {CVPR 2016},
}

@misc{cnn-semantic-2,
  Author = {Qing Li and Xiaojiang Peng and Yu Qiao and Qiang Peng},
  Title = {Learning Category Correlations for Multi-label Image Recognition with Graph Networks},
  Year = {2019},
  Eprint = {arXiv:1909.13005},
}

@misc{cnn-side-1,
  Author = {Justin Johnson and Lamberto Ballan and Li Fei-Fei},
  Title = {Love Thy Neighbors: Image Annotation by Exploiting Image Metadata},
  Year = {2015},
  howpublished = {ICCV 2015}
}

@misc{cnn-side-2,
  Author = {Fengtao Zhou and Sheng Huang and Yun Xing},
  Title = {Deep Semantic Dictionary Learning for Multi-label Image Classification},
  Year = {2021},
  howpublished = {AAAI 2021}
}

@misc{cnn-side-3,
Author = {Kevin Tang and Manohar Paluri and Li Fei-Fei and Rob Fergus and Lubomir Bourdev},
Title = {Improving Image Classification with Location Context},
Year = {2015},
Eprint = {arXiv:1505.03873},
}

@ARTICLE{srn,
  title         = "Learning spatial regularization with image-level
                   supervisions for multi-label image classification",
  author        = "Zhu, Feng and Li, Hongsheng and Ouyang, Wanli and Yu,
                   Nenghai and Wang, Xiaogang",
  abstract      = "Multi-label image classification is a fundamental but
                   challenging task in computer vision. Great progress has been
                   achieved by exploiting semantic relations between labels in
                   recent years. However, conventional approaches are unable to
                   model the underlying spatial relations between labels in
                   multi-label images, because spatial annotations of the
                   labels are generally not provided. In this paper, we propose
                   a unified deep neural network that exploits both semantic
                   and spatial relations between labels with only image-level
                   supervisions. Given a multi-label image, our proposed
                   Spatial Regularization Network (SRN) generates attention
                   maps for all labels and captures the underlying relations
                   between them via learnable convolutions. By aggregating the
                   regularized classification results with original results by
                   a ResNet-101 network, the classification performance can be
                   consistently improved. The whole deep neural network is
                   trained end-to-end with only image-level annotations, thus
                   requires no additional efforts on image annotations.
                   Extensive evaluations on 3 public datasets with different
                   types of labels show that our approach significantly
                   outperforms state-of-the-arts and has strong generalization
                   capability. Analysis of the learned SRN model demonstrates
                   that it can effectively capture both semantic and spatial
                   relations of labels for improving classification
                   performance.",
  month         =  feb,
  year          =  2017,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1702.05891"
}

@ARTICLE{sr-cnn-rnn,
  title         = "Semantic Regularisation for Recurrent Image Annotation",
  author        = "Liu, Feng and Xiang, Tao and Hospedales, Timothy M and Yang,
                   Wankou and Sun, Changyin",
  abstract      = "The ``CNN-RNN'' design pattern is increasingly widely
                   applied in a variety of image annotation tasks including
                   multi-label classification and captioning. Existing models
                   use the weakly semantic CNN hidden layer or its transform as
                   the image embedding that provides the interface between the
                   CNN and RNN. This leaves the RNN overstretched with two
                   jobs: predicting the visual concepts and modelling their
                   correlations for generating structured annotation output.
                   Importantly this makes the end-to-end training of the CNN
                   and RNN slow and ineffective due to the difficulty of back
                   propagating gradients through the RNN to train the CNN. We
                   propose a simple modification to the design pattern that
                   makes learning more effective and efficient. Specifically,
                   we propose to use a semantically regularised embedding layer
                   as the interface between the CNN and RNN. Regularising the
                   interface can partially or completely decouple the learning
                   problems, allowing each to be more effectively trained and
                   jointly training much more efficient. Extensive experiments
                   show that state-of-the art performance is achieved on
                   multi-label classification as well as image captioning.",
  month         =  nov,
  year          =  2016,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1611.05490"
}


@InProceedings{cnn-rnn,
author = {Wei Wang and Jiang and Yang and Yi and Mao and Junhua and Huang and Zhiheng and Huang and Chang and Xu},
title = {CNN-RNN: A Unified Framework for Multi-Label Image Classification},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@misc{resnet,
Author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
Title = {Deep Residual Learning for Image Recognition},
Year = {2015},
Eprint = {arXiv:1512.03385},
}

@ARTICLE{resnext,
  title         = "Aggregated residual transformations for deep neural networks",
  author        = "Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and
                   Tu, Zhuowen and He, Kaiming",
  abstract      = "We present a simple, highly modularized network architecture
                   for image classification. Our network is constructed by
                   repeating a building block that aggregates a set of
                   transformations with the same topology. Our simple design
                   results in a homogeneous, multi-branch architecture that has
                   only a few hyper-parameters to set. This strategy exposes a
                   new dimension, which we call ``cardinality'' (the size of
                   the set of transformations), as an essential factor in
                   addition to the dimensions of depth and width. On the
                   ImageNet-1K dataset, we empirically show that even under the
                   restricted condition of maintaining complexity, increasing
                   cardinality is able to improve classification accuracy.
                   Moreover, increasing cardinality is more effective than
                   going deeper or wider when we increase the capacity. Our
                   models, named ResNeXt, are the foundations of our entry to
                   the ILSVRC 2016 classification task in which we secured 2nd
                   place. We further investigate ResNeXt on an ImageNet-5K set
                   and the COCO detection set, also showing better results than
                   its ResNet counterpart. The code and models are publicly
                   available online.",
  month         =  nov,
  year          =  2016,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1611.05431"
}

@inproceedings{alexnet,
 author = {Krizhevsky Alex and Sutskever Ilya and Hinton Geoffrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{googlenet,
Author = {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
Title = {Going Deeper with Convolutions},
Year = {2014},
Eprint = {arXiv:1409.4842},
}

@misc{cnn-labeling-1,
  author = {Yunchao Gong and Yangqing Jia and Thomas Leung and Alexander Toshev and Sergey Ioffe},
  title = {Deep Convolutional Ranking for Multilabel Image Annotation},
  year = {2013},
  eprint = {arXiv:1312.4894},
}

@article{cnn-labeling-2,
Author = {Yunchao Wei and Wei Xia and Junshi Huang and Bingbing Ni and Jian Dong and Yao Zhao and Shuicheng Yan},
Title = {CNN: Single-label to Multi-label},
Year = {2014},
Eprint = {arXiv:1406.5726},
Doi = {10.1109/TPAMI.2015.2491929},
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Li Deng and Jia Dong and Wei Socher and Richard Li and Li-Jia Li and Kai Fei-Fei},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@article{cocodataset,
  author    = {Tsung{-}Yi Lin and Michael Maire and Serge J. Belongie and Lubomir D. Bourdev and Ross B. Girshick and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{'{a} }r and C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1405.0312},
  archivePrefix = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{nus-wide-civr09,
  author={Tat-Seng Chua and Jinhui Tang and Richang Hong and Haojie Li and Zhiping Luo and Yan-Tao Zheng},
  booktitle={Proc. of ACM Conf. on Image and Video Retrieval (CIVR'09)},
  posted-at={July 8-10, 2009},
  title={NUS-WIDE: A Real-World Web Image Database from National University of Singapore},
  address={Santorini, Greece. },
  year={July 8-10, 2009}
}
