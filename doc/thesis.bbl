% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nyt/global//global/global}
    \entry{alexnet}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=1b959ad402bd62e529ffcdaa8e20a502}{%
           family={Alex},
           familyi={A\bibinitperiod},
           given={Krizhevsky},
           giveni={K\bibinitperiod}}}%
        {{hash=b02f7871db6fc5524cec4ce38e104410}{%
           family={Ilya},
           familyi={I\bibinitperiod},
           given={Sutskever},
           giveni={S\bibinitperiod}}}%
        {{hash=cd1f1f13f44ac517ca5bf228cd69d4b4}{%
           family={Geoffrey},
           familyi={G\bibinitperiod},
           given={Hinton},
           giveni={H\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=128472f7930be2fd0645b02dc02aaeb8}{%
           family={Pereira},
           familyi={P\bibinitperiod},
           given={F.},
           giveni={F\bibinitperiod}}}%
        {{hash=270087258d6a002033f05032fbdf6fad}{%
           family={Burges},
           familyi={B\bibinitperiod},
           given={C.J.},
           giveni={C\bibinitperiod}}}%
        {{hash=bbfb0f3936c83b7b099561e6f0e32ef3}{%
           family={Bottou},
           familyi={B\bibinitperiod},
           given={L.},
           giveni={L\bibinitperiod}}}%
        {{hash=ad5ed31dbb8d37755c6cb48bedfdfe1d}{%
           family={Weinberger},
           familyi={W\bibinitperiod},
           given={K.Q.},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{93e913bdad09c88e27e133912f5d6fa9}
      \strng{fullhash}{93e913bdad09c88e27e133912f5d6fa9}
      \strng{bibnamehash}{93e913bdad09c88e27e133912f5d6fa9}
      \strng{authorbibnamehash}{93e913bdad09c88e27e133912f5d6fa9}
      \strng{authornamehash}{93e913bdad09c88e27e133912f5d6fa9}
      \strng{authorfullhash}{93e913bdad09c88e27e133912f5d6fa9}
      \strng{editorbibnamehash}{6d86a4a427d6d8717a2b98ed4d40921c}
      \strng{editornamehash}{6d86a4a427d6d8717a2b98ed4d40921c}
      \strng{editorfullhash}{7d78cfe0216557561ed3a11320faaa87}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Advances in Neural Information Processing Systems}
      \field{title}{ImageNet Classification with Deep Convolutional Neural Networks}
      \field{volume}{25}
      \field{year}{2012}
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
      \endverb
    \endentry
    \entry{nus-wide-civr09}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=57e4257ea3484acff91be2a3df96d16b}{%
           family={Chua},
           familyi={C\bibinitperiod},
           given={Tat-Seng},
           giveni={T\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=4c9157227cef6d36d443ce936935d128}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Jinhui},
           giveni={J\bibinitperiod}}}%
        {{hash=383491f887acc2dc4bf1c772728943da}{%
           family={Hong},
           familyi={H\bibinitperiod},
           given={Richang},
           giveni={R\bibinitperiod}}}%
        {{hash=519c47e1ac25bb285467c3358b7901cb}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Haojie},
           giveni={H\bibinitperiod}}}%
        {{hash=99f5b2485a8f078ba441273bd24c40a2}{%
           family={Luo},
           familyi={L\bibinitperiod},
           given={Zhiping},
           giveni={Z\bibinitperiod}}}%
        {{hash=93513cdcc84d8da28c5bda6e102f08b5}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Yan-Tao},
           giveni={Y\bibinithyphendelim T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Santorini, Greece.}%
      }
      \strng{namehash}{7ee5e313d202e4dbec9a975ab38cba6a}
      \strng{fullhash}{3fd1a7ad72383a24e0e3ee6345934e61}
      \strng{bibnamehash}{7ee5e313d202e4dbec9a975ab38cba6a}
      \strng{authorbibnamehash}{7ee5e313d202e4dbec9a975ab38cba6a}
      \strng{authornamehash}{7ee5e313d202e4dbec9a975ab38cba6a}
      \strng{authorfullhash}{3fd1a7ad72383a24e0e3ee6345934e61}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proc. of ACM Conf. on Image and Video Retrieval (CIVR'09)}
      \field{title}{NUS-WIDE: A Real-World Web Image Database from National University of Singapore}
      \field{year}{July 8-10, 2009}
    \endentry
    \entry{dnn-cls}{article}{}
      \name{author}{3}{}{%
        {{hash=b44d52b65e72fd8ceb4f0fe71c2d13b5}{%
           family={Cire≈üan},
           familyi={C\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod}}}%
        {{hash=be71dea014b345d130231579ad7a5115}{%
           family={Meier},
           familyi={M\bibinitperiod},
           given={Ueli},
           giveni={U\bibinitperiod}}}%
        {{hash=2333709f91a1b22edafa71582c31e391}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={Juergen},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{9fef942f24e57a49a7c7bdcc0614af99}
      \strng{fullhash}{9fef942f24e57a49a7c7bdcc0614af99}
      \strng{bibnamehash}{9fef942f24e57a49a7c7bdcc0614af99}
      \strng{authorbibnamehash}{9fef942f24e57a49a7c7bdcc0614af99}
      \strng{authornamehash}{9fef942f24e57a49a7c7bdcc0614af99}
      \strng{authorfullhash}{9fef942f24e57a49a7c7bdcc0614af99}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{title}{Multi-column deep neural networks for image classification}
      \field{year}{2012}
      \verb{eprint}
      \verb 1202.2745
      \endverb
    \endentry
    \entry{deng2009imagenet}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=2f5fbdc5c3cf91f62a64663cd72397b3}{%
           family={Deng},
           familyi={D\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
        {{hash=f3fe6b12b13b14fda44a0c8987a09c9c}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Jia},
           giveni={J\bibinitperiod}}}%
        {{hash=8cc0f01d777f94aed0d1857f862c334b}{%
           family={Socher},
           familyi={S\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=f646f91b88aab9b732bdc81c0f295705}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=2afdae52015b97674d81efea449edce2}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Li-Jia},
           giveni={L\bibinithyphendelim J\bibinitperiod}}}%
        {{hash=46117f30616512e9008a7d28f57a9bf3}{%
           family={Fei-Fei},
           familyi={F\bibinithyphendelim F\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
      }
      \list{organization}{1}{%
        {Ieee}%
      }
      \strng{namehash}{4cb9920753c74fbf9110c1496b20b314}
      \strng{fullhash}{120a67996e2c3e5198c32b6199134f86}
      \strng{bibnamehash}{4cb9920753c74fbf9110c1496b20b314}
      \strng{authorbibnamehash}{4cb9920753c74fbf9110c1496b20b314}
      \strng{authornamehash}{4cb9920753c74fbf9110c1496b20b314}
      \strng{authorfullhash}{120a67996e2c3e5198c32b6199134f86}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2009 IEEE conference on computer vision and pattern recognition}
      \field{title}{Imagenet: A large-scale hierarchical image database}
      \field{year}{2009}
      \field{pages}{248\bibrangedash 255}
      \range{pages}{8}
    \endentry
    \entry{vit}{article}{}
      \name{author}{12}{}{%
        {{hash=72308762399d6ab62bbd9391c64c7bfd}{%
           family={Dosovitskiy},
           familyi={D\bibinitperiod},
           given={Alexey},
           giveni={A\bibinitperiod}}}%
        {{hash=836254958eac09b30d45dd67a75ce4fa}{%
           family={Beyer},
           familyi={B\bibinitperiod},
           given={Lucas},
           giveni={L\bibinitperiod}}}%
        {{hash=6807e3c00242c6bf6a3179905040471b}{%
           family={Kolesnikov},
           familyi={K\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=b398fca6879fde89a032b8e7de2f26b5}{%
           family={Weissenborn},
           familyi={W\bibinitperiod},
           given={Dirk},
           giveni={D\bibinitperiod}}}%
        {{hash=00b950307c7d096765bb6df00c7c5c3a}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Xiaohua},
           giveni={X\bibinitperiod}}}%
        {{hash=1a47640139e63b9b5969c969dfe95def}{%
           family={Unterthiner},
           familyi={U\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=965baf6fa5686a42b1564330c5e11f2f}{%
           family={Dehghani},
           familyi={D\bibinitperiod},
           given={Mostafa},
           giveni={M\bibinitperiod}}}%
        {{hash=06829adce8713f0ace444279dcd7328f}{%
           family={Minderer},
           familyi={M\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
        {{hash=c95269b4a2e23e1e526be521c7ec6ad4}{%
           family={Heigold},
           familyi={H\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod}}}%
        {{hash=450963f966620925cb8fecd32f7a6ee1}{%
           family={Gelly},
           familyi={G\bibinitperiod},
           given={Sylvain},
           giveni={S\bibinitperiod}}}%
        {{hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
        {{hash=493a532418540859dca92cf3b579de2a}{%
           family={Houlsby},
           familyi={H\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{d96316bc7578db680aba71d4226354c8}
      \strng{fullhash}{b8c06eaeb698f61fc96ff3e5570552ec}
      \strng{bibnamehash}{d96316bc7578db680aba71d4226354c8}
      \strng{authorbibnamehash}{d96316bc7578db680aba71d4226354c8}
      \strng{authornamehash}{d96316bc7578db680aba71d4226354c8}
      \strng{authorfullhash}{b8c06eaeb698f61fc96ff3e5570552ec}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{title}{An image is worth 16x16 words: Transformers for image recognition at scale}
      \field{year}{2020}
      \verb{eprint}
      \verb 2010.11929
      \endverb
    \endentry
    \entry{cnn-labeling}{misc}{}
      \name{author}{5}{}{%
        {{hash=59205e0d2250b7d12f67789523151cb2}{%
           family={Gong},
           familyi={G\bibinitperiod},
           given={Yunchao},
           giveni={Y\bibinitperiod}}}%
        {{hash=9fce03efe6b3331a1b93ed2e7c0da9d5}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Yangqing},
           giveni={Y\bibinitperiod}}}%
        {{hash=909cc514625b20b174a78f5dcd8e558a}{%
           family={Leung},
           familyi={L\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=1ee35bc00bbae520d60769a153d7a5de}{%
           family={Toshev},
           familyi={T\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=5543e82359e26b035efc009cb3efff9d}{%
           family={Ioffe},
           familyi={I\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{ed66f0d867893e563fcbdb51638b2715}
      \strng{fullhash}{9531655c3b47b87634071777c8022634}
      \strng{bibnamehash}{ed66f0d867893e563fcbdb51638b2715}
      \strng{authorbibnamehash}{ed66f0d867893e563fcbdb51638b2715}
      \strng{authornamehash}{ed66f0d867893e563fcbdb51638b2715}
      \strng{authorfullhash}{9531655c3b47b87634071777c8022634}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Deep Convolutional Ranking for Multilabel Image Annotation}
      \field{year}{2013}
      \verb{eprint}
      \verb arXiv:1312.4894
      \endverb
    \endentry
    \entry{resnet}{article}{}
      \name{author}{4}{}{%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
        {{hash=5e72bc22dbcf0984c6d113d280e36990}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiangyu},
           giveni={X\bibinitperiod}}}%
        {{hash=bb295293acacd54387339079ebbe4ead}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Shaoqing},
           giveni={S\bibinitperiod}}}%
        {{hash=f85751488058842b5777c7b4074077b5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \strng{bibnamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorbibnamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{title}{Deep residual learning for image recognition}
      \field{year}{2015}
      \verb{eprint}
      \verb 1512.03385
      \endverb
    \endentry
    \entry{cnn-sinn}{article}{}
      \name{author}{5}{}{%
        {{hash=dff8e0e983ddbd664385519a3124a56a}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Hexiang},
           giveni={H\bibinitperiod}}}%
        {{hash=c2a31b47a5c7a40f28ba83b865eec416}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Guang-Tong},
           giveni={G\bibinithyphendelim T\bibinitperiod}}}%
        {{hash=05ee45fb544d0c9d90184945bbd82dd1}{%
           family={Deng},
           familyi={D\bibinitperiod},
           given={Zhiwei},
           giveni={Z\bibinitperiod}}}%
        {{hash=e238e99f7fa075ced243ed36b46917b2}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Zicheng},
           giveni={Z\bibinitperiod}}}%
        {{hash=666c12517626c817b8d3a1ba792fc2c2}{%
           family={Mori},
           familyi={M\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{6588b312e8e905296af8584ba1df8eb6}
      \strng{fullhash}{4a1f595ee3c31d84392e50cab80015a2}
      \strng{bibnamehash}{6588b312e8e905296af8584ba1df8eb6}
      \strng{authorbibnamehash}{6588b312e8e905296af8584ba1df8eb6}
      \strng{authornamehash}{6588b312e8e905296af8584ba1df8eb6}
      \strng{authorfullhash}{4a1f595ee3c31d84392e50cab80015a2}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Images of scenes have various objects as well as abundant attributes, and diverse levels of visual categorization are possible. A natural image could be assigned with fine-grained labels that describe major components, coarse-grained labels that depict high level abstraction or a set of labels that reveal attributes. Such categorization at different concept layers can be modeled with label graphs encoding label information. In this paper, we exploit this rich information with a state-of-art deep learning framework, and propose a generic structured model that leverages diverse label relations to improve image classification performance. Our approach employs a novel stacked label prediction neural network, capturing both inter-level and intra-level label semantics. We evaluate our method on benchmark image datasets, and empirical results illustrate the efficacy of our model.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{title}{Learning structured inference neural networks with label relations}
      \field{year}{2015}
      \verb{eprint}
      \verb 1511.05616
      \endverb
    \endentry
    \entry{cnn-neighbors}{article}{}
      \name{author}{3}{}{%
        {{hash=90edc587e1d523d4e173b1fe6e733445}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod}}}%
        {{hash=7df8548b5904fc2351c3211293b17048}{%
           family={Ballan},
           familyi={B\bibinitperiod},
           given={Lamberto},
           giveni={L\bibinitperiod}}}%
        {{hash=9147b1a8523fee33e02ea8ada6fde536}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Fei-Fei},
           giveni={F\bibinithyphendelim F\bibinitperiod}}}%
      }
      \strng{namehash}{631a7a667c9d3221f7f96f9b8b0d64e9}
      \strng{fullhash}{631a7a667c9d3221f7f96f9b8b0d64e9}
      \strng{bibnamehash}{631a7a667c9d3221f7f96f9b8b0d64e9}
      \strng{authorbibnamehash}{631a7a667c9d3221f7f96f9b8b0d64e9}
      \strng{authornamehash}{631a7a667c9d3221f7f96f9b8b0d64e9}
      \strng{authorfullhash}{631a7a667c9d3221f7f96f9b8b0d64e9}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Some images that are difficult to recognize on their own may become more clear in the context of a neighborhood of related images with similar social-network metadata. We build on this intuition to improve multilabel image annotation. Our model uses image metadata nonparametrically to generate neighborhoods of related images using Jaccard similarities, then uses a deep neural network to blend visual information from the image and its neighbors. Prior work typically models image metadata parametrically, in contrast, our nonparametric treatment allows our model to perform well even when the vocabulary of metadata changes between training and testing. We perform comprehensive experiments on the NUS-WIDE dataset, where we show that our model outperforms state-of-the-art methods for multilabel image annotation even when our model is forced to generalize to new types of metadata.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{8}
      \field{title}{Love thy neighbors: Image annotation by exploiting image metadata}
      \field{year}{2015}
      \verb{eprint}
      \verb 1508.07647
      \endverb
    \endentry
    \entry{cocodataset}{article}{}
      \name{author}{10}{}{%
        {{hash=08f925fe4692d130a1d7cb7d94483351}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Tsung{-}Yi},
           giveni={T\bibinitperiod}}}%
        {{hash=d980bc6930f008a0fb5fa667785f2309}{%
           family={Maire},
           familyi={M\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=8f74ba6d25e498a6a4044b39ee30c903}{%
           family={Belongie},
           familyi={B\bibinitperiod},
           given={Serge\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=41d1867a5948033a654e06e5a0c87f22}{%
           family={Bourdev},
           familyi={B\bibinitperiod},
           given={Lubomir\bibnamedelima D.},
           giveni={L\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=c2c60ceb4a241891e128295a5ae80aef}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross\bibnamedelima B.},
           giveni={R\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=797fc3624ba315db58eef7279ace5bf3}{%
           family={Hays},
           familyi={H\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=e52876f830a8a20786ff3e4d7dd6f083}{%
           family={Perona},
           familyi={P\bibinitperiod},
           given={Pietro},
           giveni={P\bibinitperiod}}}%
        {{hash=aedcd3831845183e070aef16857d83ea}{%
           family={Ramanan},
           familyi={R\bibinitperiod},
           given={Deva},
           giveni={D\bibinitperiod}}}%
        {{hash=6b40d5bf80eb409d7c532ad93385ea4b}{%
           family={Doll{'{a}\bibnamedelimb }r},
           familyi={D\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod}}}%
        {{hash=0eae2d56a9cbb037c64028d6573877a7}{%
           family={Zitnick},
           familyi={Z\bibinitperiod},
           given={C.\bibnamedelimi Lawrence},
           giveni={C\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{3b7e00bc88d7aca4d4d5ddb8c252e36c}
      \strng{fullhash}{abe00938784092380c5c50b520db4b44}
      \strng{bibnamehash}{3b7e00bc88d7aca4d4d5ddb8c252e36c}
      \strng{authorbibnamehash}{3b7e00bc88d7aca4d4d5ddb8c252e36c}
      \strng{authornamehash}{3b7e00bc88d7aca4d4d5ddb8c252e36c}
      \strng{authorfullhash}{abe00938784092380c5c50b520db4b44}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{CoRR}
      \field{title}{Microsoft {COCO:} Common Objects in Context}
      \field{volume}{abs/1405.0312}
      \field{year}{2014}
      \verb{eprint}
      \verb 1405.0312
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1405.0312
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1405.0312
      \endverb
    \endentry
    \entry{sr-cnn-rnn}{article}{}
      \name{author}{5}{}{%
        {{hash=8cfebbe54197d0a6e7c196b6fe8cf3a3}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Feng},
           giveni={F\bibinitperiod}}}%
        {{hash=20de9f859b0b9bfb12fa85f3513c2fc1}{%
           family={Xiang},
           familyi={X\bibinitperiod},
           given={Tao},
           giveni={T\bibinitperiod}}}%
        {{hash=925f77faddc6019beb9b26a56fe09e0c}{%
           family={Hospedales},
           familyi={H\bibinitperiod},
           given={Timothy\bibnamedelima M},
           giveni={T\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=f0d566688f8ace36fba22c1f9ddcfcab}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Wankou},
           giveni={W\bibinitperiod}}}%
        {{hash=0745e86e005954362910b8a4c4ddf7e4}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Changyin},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{53cf3057a5afe39f80bc6c1fdf9a86d8}
      \strng{fullhash}{b0dd3d51eac20e59f6f4f1e3e4934496}
      \strng{bibnamehash}{53cf3057a5afe39f80bc6c1fdf9a86d8}
      \strng{authorbibnamehash}{53cf3057a5afe39f80bc6c1fdf9a86d8}
      \strng{authornamehash}{53cf3057a5afe39f80bc6c1fdf9a86d8}
      \strng{authorfullhash}{b0dd3d51eac20e59f6f4f1e3e4934496}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The ``CNN-RNN'' design pattern is increasingly widely applied in a variety of image annotation tasks including multi-label classification and captioning. Existing models use the weakly semantic CNN hidden layer or its transform as the image embedding that provides the interface between the CNN and RNN. This leaves the RNN overstretched with two jobs: predicting the visual concepts and modelling their correlations for generating structured annotation output. Importantly this makes the end-to-end training of the CNN and RNN slow and ineffective due to the difficulty of back propagating gradients through the RNN to train the CNN. We propose a simple modification to the design pattern that makes learning more effective and efficient. Specifically, we propose to use a semantically regularised embedding layer as the interface between the CNN and RNN. Regularising the interface can partially or completely decouple the learning problems, allowing each to be more effectively trained and jointly training much more efficient. Extensive experiments show that state-of-the art performance is achieved on multi-label classification as well as image captioning.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{title}{Semantic Regularisation for Recurrent Image Annotation}
      \field{year}{2016}
      \verb{eprint}
      \verb 1611.05490
      \endverb
    \endentry
    \entry{q2l}{article}{}
      \name{author}{5}{}{%
        {{hash=06c22077b0161cb27347bb6f691e38fc}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Shilong},
           giveni={S\bibinitperiod}}}%
        {{hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod}}}%
        {{hash=9d362588e629aea5809440133ff290d7}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiao},
           giveni={X\bibinitperiod}}}%
        {{hash=3768537b732a0e6eeac046def7c74b4c}{%
           family={Su},
           familyi={S\bibinitperiod},
           given={Hang},
           giveni={H\bibinitperiod}}}%
        {{hash=7a47a154652ccc647a0e6adf1570095a}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{683dedfa8c48cdc047fa4a4386668ce9}
      \strng{fullhash}{fda3855b999e06dcd66547a681a08eaf}
      \strng{bibnamehash}{683dedfa8c48cdc047fa4a4386668ce9}
      \strng{authorbibnamehash}{683dedfa8c48cdc047fa4a4386668ce9}
      \strng{authornamehash}{683dedfa8c48cdc047fa4a4386668ce9}
      \strng{authorfullhash}{fda3855b999e06dcd66547a681a08eaf}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents a simple and effective approach to solving the multi-label classification problem. The proposed approach leverages Transformer decoders to query the existence of a class label. The use of Transformer is rooted in the need of extracting local discriminative features adaptively for different labels, which is a strongly desired property due to the existence of multiple objects in one image. The built-in cross-attention module in the Transformer decoder offers an effective way to use label embeddings as queries to probe and pool class-related features from a feature map computed by a vision backbone for subsequent binary classifications. Compared with prior works, the new framework is simple, using standard Transformers and vision backbones, and effective, consistently outperforming all previous works on five multi-label classification data sets, including MS-COCO, PASCAL VOC, NUS-WIDE, and Visual Genome. Particularly, we establish $91.3\%$ mAP on MS-COCO. We hope its compact structure, simple implementation, and superior performance serve as a strong baseline for multi-label classification tasks and future studies. The code will be available soon at https://github.com/SlongLiu/query2labels.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{7}
      \field{title}{{Query2Label}: A Simple Transformer Way to {Multi-Label} Classification}
      \field{year}{2021}
      \verb{eprint}
      \verb 2107.10834
      \endverb
    \endentry
    \entry{mixed-precision}{article}{}
      \name{author}{11}{}{%
        {{hash=d7c3b32c10d0f73ef681b6074aa1cdd4}{%
           family={Micikevicius},
           familyi={M\bibinitperiod},
           given={Paulius},
           giveni={P\bibinitperiod}}}%
        {{hash=a2da348cbbad750c6fe76dda9c35ffcd}{%
           family={Narang},
           familyi={N\bibinitperiod},
           given={Sharan},
           giveni={S\bibinitperiod}}}%
        {{hash=2775ac930f1eb8512a1187294d6fcb98}{%
           family={Alben},
           familyi={A\bibinitperiod},
           given={Jonah},
           giveni={J\bibinitperiod}}}%
        {{hash=fe0b5c62f5fbbcbe8b3b69115795d3e5}{%
           family={Diamos},
           familyi={D\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod}}}%
        {{hash=6aa92a937d4d30dd0b5ec0eecbad1bf1}{%
           family={Elsen},
           familyi={E\bibinitperiod},
           given={Erich},
           giveni={E\bibinitperiod}}}%
        {{hash=390131310e5498d8c5fa5414afdc5f26}{%
           family={Garcia},
           familyi={G\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=57b6ee8703cf89267a2d51429a4e61a7}{%
           family={Ginsburg},
           familyi={G\bibinitperiod},
           given={Boris},
           giveni={B\bibinitperiod}}}%
        {{hash=e9b08b237b71fda19c9d090f30b37e4b}{%
           family={Houston},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=bf07d85e23f5d109ed19745b901d2ce8}{%
           family={Kuchaiev},
           familyi={K\bibinitperiod},
           given={Oleksii},
           giveni={O\bibinitperiod}}}%
        {{hash=d3fa1f906f9b4c19fe8931015c8908da}{%
           family={Venkatesh},
           familyi={V\bibinitperiod},
           given={Ganesh},
           giveni={G\bibinitperiod}}}%
        {{hash=d0d5a12b1f5bae45ea7780158b3b35c8}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{edba223ee55e56879fca40d7bf77b7dc}
      \strng{fullhash}{fc75d779136c36bfa2f39068ce45bbba}
      \strng{bibnamehash}{edba223ee55e56879fca40d7bf77b7dc}
      \strng{authorbibnamehash}{edba223ee55e56879fca40d7bf77b7dc}
      \strng{authornamehash}{edba223ee55e56879fca40d7bf77b7dc}
      \strng{authorfullhash}{fc75d779136c36bfa2f39068ce45bbba}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep neural networks have enabled progress in a wide variety of applications. Growing the size of the neural network typically results in improved accuracy. As model sizes grow, the memory and compute requirements for training these models also increases. We introduce a technique to train deep neural networks using half precision floating point numbers. In our technique, weights, activations and gradients are stored in IEEE half-precision format. Half-precision floating numbers have limited numerical range compared to single-precision numbers. We propose two techniques to handle this loss of information. Firstly, we recommend maintaining a single-precision copy of the weights that accumulates the gradients after each optimizer step. This single-precision copy is rounded to half-precision format during training. Secondly, we propose scaling the loss appropriately to handle the loss of information with half-precision gradients. We demonstrate that this approach works for a wide variety of models including convolution neural networks, recurrent neural networks and generative adversarial networks. This technique works for large scale models with more than 100 million parameters trained on large datasets. Using this approach, we can reduce the memory consumption of deep learning models by nearly 2x. In future processors, we can also expect a significant computation speedup using half-precision hardware units.}
      \field{eprintclass}{cs.AI}
      \field{eprinttype}{arXiv}
      \field{month}{10}
      \field{title}{Mixed Precision Training}
      \field{year}{2017}
      \verb{eprint}
      \verb 1710.03740
      \endverb
    \endentry
    \entry{cnn-cls-2}{article}{}
      \name{author}{2}{}{%
        {{hash=f92af5765968c6de4c1e42d397224c9c}{%
           family={O'Shea},
           familyi={O\bibinitperiod},
           given={Keiron},
           giveni={K\bibinitperiod}}}%
        {{hash=b5da23fc726b6d32ee9a3247fa6663fc}{%
           family={Nash},
           familyi={N\bibinitperiod},
           given={Ryan},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{1e0b31097f3d41e61dd78e46b147642a}
      \strng{fullhash}{1e0b31097f3d41e61dd78e46b147642a}
      \strng{bibnamehash}{1e0b31097f3d41e61dd78e46b147642a}
      \strng{authorbibnamehash}{1e0b31097f3d41e61dd78e46b147642a}
      \strng{authornamehash}{1e0b31097f3d41e61dd78e46b147642a}
      \strng{authorfullhash}{1e0b31097f3d41e61dd78e46b147642a}
      \field{sortinit}{O}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.}
      \field{eprintclass}{cs.NE}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{title}{An Introduction to Convolutional Neural Networks}
      \field{year}{2015}
      \verb{eprint}
      \verb 1511.08458
      \endverb
    \endentry
    \entry{cnn-cls-1}{article}{}
      \name{author}{2}{}{%
        {{hash=9d16b7284df92c9adaee86c37ab992df}{%
           family={Simonyan},
           familyi={S\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod}}}%
        {{hash=c72fc39e94030f67717052309266a44d}{%
           family={Zisserman},
           familyi={Z\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{25d2f3c4577a6632d37f0126cc781232}
      \strng{fullhash}{25d2f3c4577a6632d37f0126cc781232}
      \strng{bibnamehash}{25d2f3c4577a6632d37f0126cc781232}
      \strng{authorbibnamehash}{25d2f3c4577a6632d37f0126cc781232}
      \strng{authornamehash}{25d2f3c4577a6632d37f0126cc781232}
      \strng{authorfullhash}{25d2f3c4577a6632d37f0126cc781232}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{9}
      \field{title}{Very deep convolutional networks for large-scale image recognition}
      \field{year}{2014}
      \verb{eprint}
      \verb 1409.1556
      \endverb
    \endentry
    \entry{dropout}{article}{}
      \name{author}{5}{}{%
        {{hash=6a147afa4569ce6cf23c0436e65d8486}{%
           family={Srivastava},
           familyi={S\bibinitperiod},
           given={Nitish},
           giveni={N\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=bd2be300d445e9f6db7808f9533e66cb}{%
           family={Salakhutdinov},
           familyi={S\bibinitperiod},
           given={Ruslan},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{fullhash}{2850768171a28ccacd146c300f66f57d}
      \strng{bibnamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authorbibnamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authornamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authorfullhash}{2850768171a28ccacd146c300f66f57d}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{56}
      \field{title}{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}
      \field{volume}{15}
      \field{year}{2014}
      \field{pages}{1929\bibrangedash 1958}
      \range{pages}{30}
      \verb{urlraw}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
      \verb{url}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
    \endentry
    \entry{googlenet}{misc}{}
      \name{author}{9}{}{%
        {{hash=ed568d9c3bb059e6bf22899fbf170f86}{%
           family={Szegedy},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=c0e0d23e2d09e45e6f51cc2bcea6d9f9}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=9fce03efe6b3331a1b93ed2e7c0da9d5}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Yangqing},
           giveni={Y\bibinitperiod}}}%
        {{hash=15f5333df96deaf51c72d065bded37d8}{%
           family={Sermanet},
           familyi={S\bibinitperiod},
           given={Pierre},
           giveni={P\bibinitperiod}}}%
        {{hash=698ee61a2f3fa29734204496d2d36aef}{%
           family={Reed},
           familyi={R\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod}}}%
        {{hash=c1826f3465579186aff299a9b0e16ed7}{%
           family={Anguelov},
           familyi={A\bibinitperiod},
           given={Dragomir},
           giveni={D\bibinitperiod}}}%
        {{hash=8bbc4c5d96f205bada839e74e0202146}{%
           family={Erhan},
           familyi={E\bibinitperiod},
           given={Dumitru},
           giveni={D\bibinitperiod}}}%
        {{hash=8051922e7bd286f884bfbd1023ef62f5}{%
           family={Vanhoucke},
           familyi={V\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod}}}%
        {{hash=aa04c4d6213a1e867b1650e298cb2668}{%
           family={Rabinovich},
           familyi={R\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{80f8e6bfc3aff3e75b2807a6f6962740}
      \strng{fullhash}{64fbaf3c8a6b53523f74f0087b58e7e6}
      \strng{bibnamehash}{80f8e6bfc3aff3e75b2807a6f6962740}
      \strng{authorbibnamehash}{80f8e6bfc3aff3e75b2807a6f6962740}
      \strng{authornamehash}{80f8e6bfc3aff3e75b2807a6f6962740}
      \strng{authorfullhash}{64fbaf3c8a6b53523f74f0087b58e7e6}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Going Deeper with Convolutions}
      \field{year}{2014}
      \verb{eprint}
      \verb arXiv:1409.4842
      \endverb
    \endentry
    \entry{cnn-location}{article}{}
      \name{author}{5}{}{%
        {{hash=3609d608ecd1c366cace378920094701}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Kevin},
           giveni={K\bibinitperiod}}}%
        {{hash=d1976e858e503a89ab7e5fa48734c939}{%
           family={Paluri},
           familyi={P\bibinitperiod},
           given={Manohar},
           giveni={M\bibinitperiod}}}%
        {{hash=cd00ce5bc45f687c432e52e0fa1a7aa6}{%
           family={Fei-Fei},
           familyi={F\bibinithyphendelim F\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
        {{hash=a6784304d1cc890b2cb6c6c7f2f3fd76}{%
           family={Fergus},
           familyi={F\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod}}}%
        {{hash=a5d50cf5c085cd3a323d68588dcb89c8}{%
           family={Bourdev},
           familyi={B\bibinitperiod},
           given={Lubomir},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{eadfb55e845527dd0e7e3dc75e0e178d}
      \strng{fullhash}{9ae25058b6da77082dd46f9e084c0bb3}
      \strng{bibnamehash}{eadfb55e845527dd0e7e3dc75e0e178d}
      \strng{authorbibnamehash}{eadfb55e845527dd0e7e3dc75e0e178d}
      \strng{authornamehash}{eadfb55e845527dd0e7e3dc75e0e178d}
      \strng{authorfullhash}{9ae25058b6da77082dd46f9e084c0bb3}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the widespread availability of cellphones and cameras that have GPS capabilities, it is common for images being uploaded to the Internet today to have GPS coordinates associated with them. In addition to research that tries to predict GPS coordinates from visual features, this also opens up the door to problems that are conditioned on the availability of GPS coordinates. In this work, we tackle the problem of performing image classification with location context, in which we are given the GPS coordinates for images in both the train and test phases. We explore different ways of encoding and extracting features from the GPS coordinates, and show how to naturally incorporate these features into a Convolutional Neural Network (CNN), the current state-of-the-art for most image classification and recognition problems. We also show how it is possible to simultaneously learn the optimal pooling radii for a subset of our features within the CNN framework. To evaluate our model and to help promote research in this area, we identify a set of location-sensitive concepts and annotate a subset of the Yahoo Flickr Creative Commons 100M dataset that has GPS coordinates with these concepts, which we make publicly available. By leveraging location context, we are able to achieve almost a 7\% gain in mean average precision.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{title}{Improving image classification with location context}
      \field{year}{2015}
      \verb{eprint}
      \verb 1505.03873
      \endverb
    \endentry
    \entry{cnn-rnn}{article}{}
      \name{author}{6}{}{%
        {{hash=d79c0a25d1b013fc9e5226b9b6d422db}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jiang},
           giveni={J\bibinitperiod}}}%
        {{hash=446e84a6f09f26fc6cf5730853e551ba}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
        {{hash=a43967c24c1520bff0a43a748b2b32c3}{%
           family={Mao},
           familyi={M\bibinitperiod},
           given={Junhua},
           giveni={J\bibinitperiod}}}%
        {{hash=6e8d947dd72de23b8500095b595e1e99}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Zhiheng},
           giveni={Z\bibinitperiod}}}%
        {{hash=c579e88b7416fed9966902d191cd4775}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Chang},
           giveni={C\bibinitperiod}}}%
        {{hash=b1dd1a9ff59cc6aeba590fc68bcc39cf}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{8d74e80483ca0b99169002f34fa82347}
      \strng{fullhash}{bc8ac76751877f987823ae410cba570e}
      \strng{bibnamehash}{8d74e80483ca0b99169002f34fa82347}
      \strng{authorbibnamehash}{8d74e80483ca0b99169002f34fa82347}
      \strng{authornamehash}{8d74e80483ca0b99169002f34fa82347}
      \strng{authorfullhash}{bc8ac76751877f987823ae410cba570e}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While deep convolutional neural networks (CNNs) have shown a great success in single-label image classification, it is important to note that real world images generally contain multiple labels, which could correspond to different objects, scenes, actions and attributes in an image. Traditional approaches to multi-label image classification learn independent classifiers for each category and employ ranking or thresholding on the classification results. These techniques, although working well, fail to explicitly exploit the label dependencies in an image. In this paper, we utilize recurrent neural networks (RNNs) to address this problem. Combined with CNNs, the proposed CNN-RNN framework learns a joint image-label embedding to characterize the semantic label dependency as well as the image-label relevance, and it can be trained end-to-end from scratch to integrate both information in a unified framework. Experimental results on public benchmark datasets demonstrate that the proposed architecture achieves better performance than the state-of-the-art multi-label classification model}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{4}
      \field{title}{{CNN-RNN}: A unified framework for multi-label image classification}
      \field{year}{2016}
      \verb{eprint}
      \verb 1604.04573
      \endverb
    \endentry
    \entry{resnext}{article}{}
      \name{author}{5}{}{%
        {{hash=843b6293b24d49cdfdcda48e1ccd7eb3}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Saining},
           giveni={S\bibinitperiod}}}%
        {{hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod}}}%
        {{hash=ecd149fdcb3e0503881d49e545744c3d}{%
           family={Doll√°r},
           familyi={D\bibinitperiod},
           given={Piotr},
           giveni={P\bibinitperiod}}}%
        {{hash=4744828ab0e3408b2e6fc8320f7bda86}{%
           family={Tu},
           familyi={T\bibinitperiod},
           given={Zhuowen},
           giveni={Z\bibinitperiod}}}%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{b3dacadf235d95d37496872959ddcf95}
      \strng{fullhash}{ef8d2103dbe8bb0e130830c8b6543665}
      \strng{bibnamehash}{b3dacadf235d95d37496872959ddcf95}
      \strng{authorbibnamehash}{b3dacadf235d95d37496872959ddcf95}
      \strng{authornamehash}{b3dacadf235d95d37496872959ddcf95}
      \strng{authorfullhash}{ef8d2103dbe8bb0e130830c8b6543665}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call ``cardinality'' (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{title}{Aggregated residual transformations for deep neural networks}
      \field{year}{2016}
      \verb{eprint}
      \verb 1611.05431
      \endverb
    \endentry
    \entry{cpsd}{article}{}
      \name{author}{6}{}{%
        {{hash=9ddb01fd3e1cde381907410236578c2a}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Jiazhi},
           giveni={J\bibinitperiod}}}%
        {{hash=c2a7ced72472992536b07322cfad02a1}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Sheng},
           giveni={S\bibinitperiod}}}%
        {{hash=0bd4f3fadcd574f306518d5b9324ea63}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Fengtao},
           giveni={F\bibinitperiod}}}%
        {{hash=9382de42922f40f3ad1348cce244604e}{%
           family={Huangfu},
           familyi={H\bibinitperiod},
           given={Luwen},
           giveni={L\bibinitperiod}}}%
        {{hash=510c9ed1656d5f53aabf3eb8b57c2480}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=fa97927921a403cfe822973e31081dca}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{25d1643e29c4b6c24cc0033b21ec601d}
      \strng{fullhash}{fc5cc166cb8d039a9974eb0f5ffa7dc8}
      \strng{bibnamehash}{25d1643e29c4b6c24cc0033b21ec601d}
      \strng{authorbibnamehash}{25d1643e29c4b6c24cc0033b21ec601d}
      \strng{authornamehash}{25d1643e29c4b6c24cc0033b21ec601d}
      \strng{authorfullhash}{fc5cc166cb8d039a9974eb0f5ffa7dc8}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multi-Label Image Classification (MLIC) approaches usually exploit label correlations to achieve good performance. However, emphasizing correlation like co-occurrence may overlook discriminative features of the target itself and lead to model overfitting, thus undermining the performance. In this study, we propose a generic framework named Parallel Self-Distillation (PSD) for boosting MLIC models. PSD decomposes the original MLIC task into several simpler MLIC sub-tasks via two elaborated complementary task decomposition strategies named Co-occurrence Graph Partition (CGP) and Dis-occurrence Graph Partition (DGP). Then, the MLIC models of fewer categories are trained with these sub-tasks in parallel for respectively learning the joint patterns and the category-specific patterns of labels. Finally, knowledge distillation is leveraged to learn a compact global ensemble of full categories with these learned patterns for reconciling the label correlation exploitation and model overfitting. Extensive results on MS-COCO and NUS-WIDE datasets demonstrate that our framework can be easily plugged into many MLIC approaches and improve performances of recent state-of-the-art approaches. The explainable visual study also further validates that our method is able to learn both the category-specific and co-occurring features. The source code is released at https://github.com/Robbie-Xu/CPSD.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{title}{Boosting multi-Label Image Classification with complementary Parallel Self-distillation}
      \field{year}{2022}
      \verb{eprint}
      \verb 2205.10986
      \endverb
    \endentry
    \entry{cma}{article}{}
      \name{author}{6}{}{%
        {{hash=ec34c7cf13514b7d0c640d0b3dd9a99e}{%
           family={You},
           familyi={Y\bibinitperiod},
           given={Renchun},
           giveni={R\bibinitperiod}}}%
        {{hash=03654e0934da1100435c81bfb7c04b1d}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Zhiyao},
           giveni={Z\bibinitperiod}}}%
        {{hash=d22cf63412f5bb89dcde7965f3514581}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod}}}%
        {{hash=39ac863f374c7369156e6853399cdd61}{%
           family={Long},
           familyi={L\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=5054b8c4c8b603b87d764608b68919cf}{%
           family={Bao},
           familyi={B\bibinitperiod},
           given={Yingze},
           giveni={Y\bibinitperiod}}}%
        {{hash=b5d524e9b0601eaffb029a504fedcf03}{%
           family={Wen},
           familyi={W\bibinitperiod},
           given={Shilei},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{4850b2047376edc92986a1d0886eab4a}
      \strng{fullhash}{15b4eed6545b3d1d0731e751baa8d7e9}
      \strng{bibnamehash}{4850b2047376edc92986a1d0886eab4a}
      \strng{authorbibnamehash}{4850b2047376edc92986a1d0886eab4a}
      \strng{authornamehash}{4850b2047376edc92986a1d0886eab4a}
      \strng{authorfullhash}{15b4eed6545b3d1d0731e751baa8d7e9}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multi-label image and video classification are fundamental yet challenging tasks in computer vision. The main challenges lie in capturing spatial or temporal dependencies between labels and discovering the locations of discriminative features for each class. In order to overcome these challenges, we propose to use cross-modality attention with semantic graph embedding for multi label classification. Based on the constructed label graph, we propose an adjacency-based similarity graph embedding method to learn semantic label embeddings, which explicitly exploit label relationships. Then our novel cross-modality attention maps are generated with the guidance of learned label embeddings. Experiments on two multi-label image classification datasets (MS-COCO and NUS-WIDE) show our method outperforms other existing state-of-the-arts. In addition, we validate our method on a large multi-label video classification dataset (YouTube-8M Segments) and the evaluation results demonstrate the generalization capability of our method.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{12}
      \field{title}{Cross-modality attention with semantic graph embedding for multi-label classification}
      \field{year}{2019}
      \verb{eprint}
      \verb 1912.07872
      \endverb
    \endentry
    \entry{srn}{article}{}
      \name{author}{5}{}{%
        {{hash=c527382ce6a2bdfc4548a1f28e479d85}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Feng},
           giveni={F\bibinitperiod}}}%
        {{hash=c727733707a60b57a65c544b07a9825e}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Hongsheng},
           giveni={H\bibinitperiod}}}%
        {{hash=dd64c5c44b678dcb01b887fcbcfedd40}{%
           family={Ouyang},
           familyi={O\bibinitperiod},
           given={Wanli},
           giveni={W\bibinitperiod}}}%
        {{hash=944469c286535032f6c946dad972fe16}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Nenghai},
           giveni={N\bibinitperiod}}}%
        {{hash=e88500bd6ca50746707a22554761b61a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiaogang},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{a01d75b0f79d0fd687dc7c4961e4ff4e}
      \strng{fullhash}{9ffc4f11670205d93d97c2fb2223f0fb}
      \strng{bibnamehash}{a01d75b0f79d0fd687dc7c4961e4ff4e}
      \strng{authorbibnamehash}{a01d75b0f79d0fd687dc7c4961e4ff4e}
      \strng{authornamehash}{a01d75b0f79d0fd687dc7c4961e4ff4e}
      \strng{authorfullhash}{9ffc4f11670205d93d97c2fb2223f0fb}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multi-label image classification is a fundamental but challenging task in computer vision. Great progress has been achieved by exploiting semantic relations between labels in recent years. However, conventional approaches are unable to model the underlying spatial relations between labels in multi-label images, because spatial annotations of the labels are generally not provided. In this paper, we propose a unified deep neural network that exploits both semantic and spatial relations between labels with only image-level supervisions. Given a multi-label image, our proposed Spatial Regularization Network (SRN) generates attention maps for all labels and captures the underlying relations between them via learnable convolutions. By aggregating the regularized classification results with original results by a ResNet-101 network, the classification performance can be consistently improved. The whole deep neural network is trained end-to-end with only image-level annotations, thus requires no additional efforts on image annotations. Extensive evaluations on 3 public datasets with different types of labels show that our approach significantly outperforms state-of-the-arts and has strong generalization capability. Analysis of the learned SRN model demonstrates that it can effectively capture both semantic and spatial relations of labels for improving classification performance.}
      \field{eprintclass}{cs.CV}
      \field{eprinttype}{arXiv}
      \field{month}{2}
      \field{title}{Learning spatial regularization with image-level supervisions for multi-label image classification}
      \field{year}{2017}
      \verb{eprint}
      \verb 1702.05891
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

